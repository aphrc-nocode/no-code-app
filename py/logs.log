2025-06-27 15:17:47,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:17:47,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:17:47,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:17:47,745:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-27 15:37:07,781:INFO:PyCaret ClassificationExperiment
2025-06-27 15:37:07,781:INFO:Logging name: clf-default-name
2025-06-27 15:37:07,781:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-27 15:37:07,781:INFO:version 3.3.2
2025-06-27 15:37:07,781:INFO:Initializing setup()
2025-06-27 15:37:07,781:INFO:self.USI: b4e1
2025-06-27 15:37:07,781:INFO:self._variable_keys: {'seed', 'fix_imbalance', 'y_test', 'gpu_n_jobs_param', 'exp_name_log', 'n_jobs_param', 'fold_generator', 'X', 'X_train', 'y', 'X_test', 'is_multiclass', 'memory', '_ml_usecase', 'USI', 'log_plots_param', 'exp_id', 'idx', 'html_param', 'gpu_param', 'target_param', 'fold_groups_param', 'y_train', '_available_plots', 'data', 'pipeline', 'logging_param', 'fold_shuffle_param'}
2025-06-27 15:37:07,781:INFO:Checking environment
2025-06-27 15:37:07,781:INFO:python_version: 3.10.4
2025-06-27 15:37:07,781:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-06-27 15:37:07,781:INFO:machine: AMD64
2025-06-27 15:37:07,824:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-27 15:37:07,830:INFO:Memory: svmem(total=16871448576, available=2182189056, percent=87.1, used=14689259520, free=2182189056)
2025-06-27 15:37:07,830:INFO:Physical Core: 10
2025-06-27 15:37:07,830:INFO:Logical Core: 12
2025-06-27 15:37:07,830:INFO:Checking libraries
2025-06-27 15:37:07,830:INFO:System:
2025-06-27 15:37:07,830:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-06-27 15:37:07,830:INFO:executable: C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\Scripts\python.exe
2025-06-27 15:37:07,830:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-27 15:37:07,830:INFO:PyCaret required dependencies:
2025-06-27 15:37:07,855:INFO:                 pip: 22.0.4
2025-06-27 15:37:07,855:INFO:          setuptools: 58.1.0
2025-06-27 15:37:07,855:INFO:             pycaret: 3.3.2
2025-06-27 15:37:07,855:INFO:             IPython: 8.37.0
2025-06-27 15:37:07,855:INFO:          ipywidgets: 8.1.7
2025-06-27 15:37:07,855:INFO:                tqdm: 4.67.1
2025-06-27 15:37:07,855:INFO:               numpy: 1.26.4
2025-06-27 15:37:07,855:INFO:              pandas: 2.1.4
2025-06-27 15:37:07,855:INFO:              jinja2: 3.1.6
2025-06-27 15:37:07,855:INFO:               scipy: 1.11.4
2025-06-27 15:37:07,855:INFO:              joblib: 1.3.2
2025-06-27 15:37:07,855:INFO:             sklearn: 1.4.2
2025-06-27 15:37:07,855:INFO:                pyod: 2.0.5
2025-06-27 15:37:07,855:INFO:            imblearn: 0.13.0
2025-06-27 15:37:07,855:INFO:   category_encoders: 2.7.0
2025-06-27 15:37:07,855:INFO:            lightgbm: 4.6.0
2025-06-27 15:37:07,855:INFO:               numba: 0.61.2
2025-06-27 15:37:07,855:INFO:            requests: 2.32.4
2025-06-27 15:37:07,855:INFO:          matplotlib: 3.7.5
2025-06-27 15:37:07,855:INFO:          scikitplot: 0.3.7
2025-06-27 15:37:07,855:INFO:         yellowbrick: 1.5
2025-06-27 15:37:07,855:INFO:              plotly: 5.24.1
2025-06-27 15:37:07,855:INFO:    plotly-resampler: Not installed
2025-06-27 15:37:07,855:INFO:             kaleido: 1.0.0
2025-06-27 15:37:07,855:INFO:           schemdraw: 0.15
2025-06-27 15:37:07,855:INFO:         statsmodels: 0.14.4
2025-06-27 15:37:07,855:INFO:              sktime: 0.26.0
2025-06-27 15:37:07,855:INFO:               tbats: 1.1.3
2025-06-27 15:37:07,855:INFO:            pmdarima: 2.0.4
2025-06-27 15:37:07,855:INFO:              psutil: 7.0.0
2025-06-27 15:37:07,855:INFO:          markupsafe: 3.0.2
2025-06-27 15:37:07,855:INFO:             pickle5: Not installed
2025-06-27 15:37:07,855:INFO:         cloudpickle: 3.1.1
2025-06-27 15:37:07,855:INFO:         deprecation: 2.1.0
2025-06-27 15:37:07,855:INFO:              xxhash: 3.5.0
2025-06-27 15:37:07,855:INFO:           wurlitzer: Not installed
2025-06-27 15:37:07,855:INFO:PyCaret optional dependencies:
2025-06-27 15:37:07,865:INFO:                shap: Not installed
2025-06-27 15:37:07,865:INFO:           interpret: Not installed
2025-06-27 15:37:07,865:INFO:                umap: Not installed
2025-06-27 15:37:07,865:INFO:     ydata_profiling: Not installed
2025-06-27 15:37:07,865:INFO:  explainerdashboard: Not installed
2025-06-27 15:37:07,865:INFO:             autoviz: Not installed
2025-06-27 15:37:07,865:INFO:           fairlearn: Not installed
2025-06-27 15:37:07,865:INFO:          deepchecks: Not installed
2025-06-27 15:37:07,865:INFO:             xgboost: Not installed
2025-06-27 15:37:07,865:INFO:            catboost: Not installed
2025-06-27 15:37:07,865:INFO:              kmodes: Not installed
2025-06-27 15:37:07,865:INFO:             mlxtend: Not installed
2025-06-27 15:37:07,865:INFO:       statsforecast: Not installed
2025-06-27 15:37:07,865:INFO:        tune_sklearn: Not installed
2025-06-27 15:37:07,865:INFO:                 ray: Not installed
2025-06-27 15:37:07,865:INFO:            hyperopt: Not installed
2025-06-27 15:37:07,865:INFO:              optuna: Not installed
2025-06-27 15:37:07,865:INFO:               skopt: Not installed
2025-06-27 15:37:07,865:INFO:              mlflow: Not installed
2025-06-27 15:37:07,865:INFO:              gradio: Not installed
2025-06-27 15:37:07,865:INFO:             fastapi: 0.115.14
2025-06-27 15:37:07,865:INFO:             uvicorn: 0.34.3
2025-06-27 15:37:07,865:INFO:              m2cgen: Not installed
2025-06-27 15:37:07,865:INFO:           evidently: Not installed
2025-06-27 15:37:07,865:INFO:               fugue: Not installed
2025-06-27 15:37:07,865:INFO:           streamlit: Not installed
2025-06-27 15:37:07,865:INFO:             prophet: Not installed
2025-06-27 15:37:07,865:INFO:None
2025-06-27 15:37:07,865:INFO:Set up data.
2025-06-27 15:37:07,900:INFO:Set up folding strategy.
2025-06-27 15:37:07,900:INFO:Set up train/test split.
2025-06-27 15:37:07,928:INFO:Set up index.
2025-06-27 15:37:07,928:INFO:Assigning column types.
2025-06-27 15:37:07,934:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-27 15:37:07,960:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 15:37:07,960:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:37:07,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:07,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-27 15:37:08,008:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:37:08,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,024:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-27 15:37:08,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:37:08,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,110:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-27 15:37:08,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,131:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-27 15:37:08,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,229:INFO:Preparing preprocessing pipeline...
2025-06-27 15:37:08,230:INFO:Set up simple imputation.
2025-06-27 15:37:08,230:INFO:Set up encoding of categorical features.
2025-06-27 15:37:08,278:INFO:Finished creating preprocessing pipeline.
2025-06-27 15:37:08,278:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-27 15:37:08,278:INFO:Creating final display dataframe.
2025-06-27 15:37:08,422:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape         (768, 10)
4        Transformed data shape         (768, 14)
5   Transformed train set shape         (537, 14)
6    Transformed test set shape         (231, 14)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              b4e1
2025-06-27 15:37:08,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-27 15:37:08,521:INFO:setup() successfully completed in 0.75s...............
2025-06-27 15:37:08,522:INFO:Initializing compare_models()
2025-06-27 15:37:08,522:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-27 15:37:08,522:INFO:Checking exceptions
2025-06-27 15:37:08,522:INFO:Preparing display monitor
2025-06-27 15:37:08,522:INFO:Initializing Logistic Regression
2025-06-27 15:37:08,522:INFO:Total runtime is 0.0 minutes
2025-06-27 15:37:08,522:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:08,522:INFO:Initializing create_model()
2025-06-27 15:37:08,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:08,522:INFO:Checking exceptions
2025-06-27 15:37:08,522:INFO:Importing libraries
2025-06-27 15:37:08,522:INFO:Copying training dataset
2025-06-27 15:37:08,533:INFO:Defining folds
2025-06-27 15:37:08,533:INFO:Declaring metric variables
2025-06-27 15:37:08,533:INFO:Importing untrained model
2025-06-27 15:37:08,533:INFO:Logistic Regression Imported successfully
2025-06-27 15:37:08,533:INFO:Starting cross validation
2025-06-27 15:37:08,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:14,707:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,716:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,756:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,784:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,886:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,902:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,904:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,941:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,953:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:14,957:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:15,058:INFO:Calculating mean and std
2025-06-27 15:37:15,058:INFO:Creating metrics dataframe
2025-06-27 15:37:15,058:INFO:Uploading results into container
2025-06-27 15:37:15,058:INFO:Uploading model into container now
2025-06-27 15:37:15,058:INFO:_master_model_container: 1
2025-06-27 15:37:15,058:INFO:_display_container: 2
2025-06-27 15:37:15,072:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-27 15:37:15,072:INFO:create_model() successfully completed......................................
2025-06-27 15:37:15,265:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:15,265:INFO:Creating metrics dataframe
2025-06-27 15:37:15,272:INFO:Initializing K Neighbors Classifier
2025-06-27 15:37:15,272:INFO:Total runtime is 0.11249287923177083 minutes
2025-06-27 15:37:15,272:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:15,272:INFO:Initializing create_model()
2025-06-27 15:37:15,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:15,272:INFO:Checking exceptions
2025-06-27 15:37:15,272:INFO:Importing libraries
2025-06-27 15:37:15,272:INFO:Copying training dataset
2025-06-27 15:37:15,275:INFO:Defining folds
2025-06-27 15:37:15,275:INFO:Declaring metric variables
2025-06-27 15:37:15,275:INFO:Importing untrained model
2025-06-27 15:37:15,275:INFO:K Neighbors Classifier Imported successfully
2025-06-27 15:37:15,275:INFO:Starting cross validation
2025-06-27 15:37:15,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:17,184:INFO:Calculating mean and std
2025-06-27 15:37:17,184:INFO:Creating metrics dataframe
2025-06-27 15:37:17,184:INFO:Uploading results into container
2025-06-27 15:37:17,184:INFO:Uploading model into container now
2025-06-27 15:37:17,184:INFO:_master_model_container: 2
2025-06-27 15:37:17,184:INFO:_display_container: 2
2025-06-27 15:37:17,184:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-27 15:37:17,184:INFO:create_model() successfully completed......................................
2025-06-27 15:37:17,258:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:17,258:INFO:Creating metrics dataframe
2025-06-27 15:37:17,258:INFO:Initializing Naive Bayes
2025-06-27 15:37:17,258:INFO:Total runtime is 0.1455952008565267 minutes
2025-06-27 15:37:17,258:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:17,258:INFO:Initializing create_model()
2025-06-27 15:37:17,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:17,258:INFO:Checking exceptions
2025-06-27 15:37:17,258:INFO:Importing libraries
2025-06-27 15:37:17,258:INFO:Copying training dataset
2025-06-27 15:37:17,266:INFO:Defining folds
2025-06-27 15:37:17,266:INFO:Declaring metric variables
2025-06-27 15:37:17,266:INFO:Importing untrained model
2025-06-27 15:37:17,266:INFO:Naive Bayes Imported successfully
2025-06-27 15:37:17,266:INFO:Starting cross validation
2025-06-27 15:37:17,266:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:17,512:INFO:Calculating mean and std
2025-06-27 15:37:17,512:INFO:Creating metrics dataframe
2025-06-27 15:37:17,512:INFO:Uploading results into container
2025-06-27 15:37:17,512:INFO:Uploading model into container now
2025-06-27 15:37:17,512:INFO:_master_model_container: 3
2025-06-27 15:37:17,517:INFO:_display_container: 2
2025-06-27 15:37:17,517:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-27 15:37:17,517:INFO:create_model() successfully completed......................................
2025-06-27 15:37:17,568:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:17,568:INFO:Creating metrics dataframe
2025-06-27 15:37:17,568:INFO:Initializing Decision Tree Classifier
2025-06-27 15:37:17,568:INFO:Total runtime is 0.15076478322347006 minutes
2025-06-27 15:37:17,568:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:17,568:INFO:Initializing create_model()
2025-06-27 15:37:17,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:17,568:INFO:Checking exceptions
2025-06-27 15:37:17,568:INFO:Importing libraries
2025-06-27 15:37:17,568:INFO:Copying training dataset
2025-06-27 15:37:17,568:INFO:Defining folds
2025-06-27 15:37:17,568:INFO:Declaring metric variables
2025-06-27 15:37:17,568:INFO:Importing untrained model
2025-06-27 15:37:17,568:INFO:Decision Tree Classifier Imported successfully
2025-06-27 15:37:17,568:INFO:Starting cross validation
2025-06-27 15:37:17,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:17,776:INFO:Calculating mean and std
2025-06-27 15:37:17,776:INFO:Creating metrics dataframe
2025-06-27 15:37:17,776:INFO:Uploading results into container
2025-06-27 15:37:17,776:INFO:Uploading model into container now
2025-06-27 15:37:17,776:INFO:_master_model_container: 4
2025-06-27 15:37:17,776:INFO:_display_container: 2
2025-06-27 15:37:17,776:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-06-27 15:37:17,776:INFO:create_model() successfully completed......................................
2025-06-27 15:37:17,818:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:17,818:INFO:Creating metrics dataframe
2025-06-27 15:37:17,834:INFO:Initializing SVM - Linear Kernel
2025-06-27 15:37:17,834:INFO:Total runtime is 0.15519236326217653 minutes
2025-06-27 15:37:17,834:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:17,834:INFO:Initializing create_model()
2025-06-27 15:37:17,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:17,834:INFO:Checking exceptions
2025-06-27 15:37:17,834:INFO:Importing libraries
2025-06-27 15:37:17,834:INFO:Copying training dataset
2025-06-27 15:37:17,834:INFO:Defining folds
2025-06-27 15:37:17,834:INFO:Declaring metric variables
2025-06-27 15:37:17,834:INFO:Importing untrained model
2025-06-27 15:37:17,834:INFO:SVM - Linear Kernel Imported successfully
2025-06-27 15:37:17,834:INFO:Starting cross validation
2025-06-27 15:37:17,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:17,998:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:18,010:INFO:Calculating mean and std
2025-06-27 15:37:18,010:INFO:Creating metrics dataframe
2025-06-27 15:37:18,010:INFO:Uploading results into container
2025-06-27 15:37:18,010:INFO:Uploading model into container now
2025-06-27 15:37:18,010:INFO:_master_model_container: 5
2025-06-27 15:37:18,010:INFO:_display_container: 2
2025-06-27 15:37:18,010:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-27 15:37:18,010:INFO:create_model() successfully completed......................................
2025-06-27 15:37:18,058:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:18,058:INFO:Creating metrics dataframe
2025-06-27 15:37:18,067:INFO:Initializing Ridge Classifier
2025-06-27 15:37:18,067:INFO:Total runtime is 0.15907477537790937 minutes
2025-06-27 15:37:18,067:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:18,067:INFO:Initializing create_model()
2025-06-27 15:37:18,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:18,067:INFO:Checking exceptions
2025-06-27 15:37:18,067:INFO:Importing libraries
2025-06-27 15:37:18,067:INFO:Copying training dataset
2025-06-27 15:37:18,068:INFO:Defining folds
2025-06-27 15:37:18,068:INFO:Declaring metric variables
2025-06-27 15:37:18,068:INFO:Importing untrained model
2025-06-27 15:37:18,068:INFO:Ridge Classifier Imported successfully
2025-06-27 15:37:18,068:INFO:Starting cross validation
2025-06-27 15:37:18,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:18,259:INFO:Calculating mean and std
2025-06-27 15:37:18,259:INFO:Creating metrics dataframe
2025-06-27 15:37:18,259:INFO:Uploading results into container
2025-06-27 15:37:18,259:INFO:Uploading model into container now
2025-06-27 15:37:18,259:INFO:_master_model_container: 6
2025-06-27 15:37:18,259:INFO:_display_container: 2
2025-06-27 15:37:18,259:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-06-27 15:37:18,259:INFO:create_model() successfully completed......................................
2025-06-27 15:37:18,310:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:18,310:INFO:Creating metrics dataframe
2025-06-27 15:37:18,316:INFO:Initializing Random Forest Classifier
2025-06-27 15:37:18,316:INFO:Total runtime is 0.16323533058166506 minutes
2025-06-27 15:37:18,317:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:18,317:INFO:Initializing create_model()
2025-06-27 15:37:18,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:18,317:INFO:Checking exceptions
2025-06-27 15:37:18,317:INFO:Importing libraries
2025-06-27 15:37:18,317:INFO:Copying training dataset
2025-06-27 15:37:18,317:INFO:Defining folds
2025-06-27 15:37:18,317:INFO:Declaring metric variables
2025-06-27 15:37:18,317:INFO:Importing untrained model
2025-06-27 15:37:18,317:INFO:Random Forest Classifier Imported successfully
2025-06-27 15:37:18,317:INFO:Starting cross validation
2025-06-27 15:37:18,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:19,088:INFO:Calculating mean and std
2025-06-27 15:37:19,088:INFO:Creating metrics dataframe
2025-06-27 15:37:19,088:INFO:Uploading results into container
2025-06-27 15:37:19,088:INFO:Uploading model into container now
2025-06-27 15:37:19,088:INFO:_master_model_container: 7
2025-06-27 15:37:19,088:INFO:_display_container: 2
2025-06-27 15:37:19,088:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-06-27 15:37:19,088:INFO:create_model() successfully completed......................................
2025-06-27 15:37:19,146:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:19,146:INFO:Creating metrics dataframe
2025-06-27 15:37:19,150:INFO:Initializing Quadratic Discriminant Analysis
2025-06-27 15:37:19,150:INFO:Total runtime is 0.17713734308878584 minutes
2025-06-27 15:37:19,150:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:19,150:INFO:Initializing create_model()
2025-06-27 15:37:19,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:19,150:INFO:Checking exceptions
2025-06-27 15:37:19,150:INFO:Importing libraries
2025-06-27 15:37:19,150:INFO:Copying training dataset
2025-06-27 15:37:19,152:INFO:Defining folds
2025-06-27 15:37:19,152:INFO:Declaring metric variables
2025-06-27 15:37:19,152:INFO:Importing untrained model
2025-06-27 15:37:19,152:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-27 15:37:19,152:INFO:Starting cross validation
2025-06-27 15:37:19,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:19,214:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,214:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,214:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,216:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,250:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,250:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,253:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,280:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,291:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,297:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-27 15:37:19,342:INFO:Calculating mean and std
2025-06-27 15:37:19,344:INFO:Creating metrics dataframe
2025-06-27 15:37:19,344:INFO:Uploading results into container
2025-06-27 15:37:19,344:INFO:Uploading model into container now
2025-06-27 15:37:19,344:INFO:_master_model_container: 8
2025-06-27 15:37:19,344:INFO:_display_container: 2
2025-06-27 15:37:19,344:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-27 15:37:19,344:INFO:create_model() successfully completed......................................
2025-06-27 15:37:19,409:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:19,409:INFO:Creating metrics dataframe
2025-06-27 15:37:19,411:INFO:Initializing Ada Boost Classifier
2025-06-27 15:37:19,411:INFO:Total runtime is 0.1814851562182109 minutes
2025-06-27 15:37:19,411:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:19,413:INFO:Initializing create_model()
2025-06-27 15:37:19,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:19,413:INFO:Checking exceptions
2025-06-27 15:37:19,413:INFO:Importing libraries
2025-06-27 15:37:19,413:INFO:Copying training dataset
2025-06-27 15:37:19,417:INFO:Defining folds
2025-06-27 15:37:19,417:INFO:Declaring metric variables
2025-06-27 15:37:19,418:INFO:Importing untrained model
2025-06-27 15:37:19,418:INFO:Ada Boost Classifier Imported successfully
2025-06-27 15:37:19,418:INFO:Starting cross validation
2025-06-27 15:37:19,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:19,487:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,491:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,495:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,506:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,506:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,533:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,536:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,550:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,559:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,571:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:19,955:INFO:Calculating mean and std
2025-06-27 15:37:19,955:INFO:Creating metrics dataframe
2025-06-27 15:37:19,957:INFO:Uploading results into container
2025-06-27 15:37:19,957:INFO:Uploading model into container now
2025-06-27 15:37:19,957:INFO:_master_model_container: 9
2025-06-27 15:37:19,957:INFO:_display_container: 2
2025-06-27 15:37:19,957:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-06-27 15:37:19,957:INFO:create_model() successfully completed......................................
2025-06-27 15:37:20,029:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:20,029:INFO:Creating metrics dataframe
2025-06-27 15:37:20,036:INFO:Initializing Gradient Boosting Classifier
2025-06-27 15:37:20,036:INFO:Total runtime is 0.1919039845466614 minutes
2025-06-27 15:37:20,036:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:20,036:INFO:Initializing create_model()
2025-06-27 15:37:20,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:20,036:INFO:Checking exceptions
2025-06-27 15:37:20,036:INFO:Importing libraries
2025-06-27 15:37:20,036:INFO:Copying training dataset
2025-06-27 15:37:20,036:INFO:Defining folds
2025-06-27 15:37:20,036:INFO:Declaring metric variables
2025-06-27 15:37:20,036:INFO:Importing untrained model
2025-06-27 15:37:20,036:INFO:Gradient Boosting Classifier Imported successfully
2025-06-27 15:37:20,036:INFO:Starting cross validation
2025-06-27 15:37:20,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:21,044:INFO:Calculating mean and std
2025-06-27 15:37:21,044:INFO:Creating metrics dataframe
2025-06-27 15:37:21,044:INFO:Uploading results into container
2025-06-27 15:37:21,044:INFO:Uploading model into container now
2025-06-27 15:37:21,044:INFO:_master_model_container: 10
2025-06-27 15:37:21,044:INFO:_display_container: 2
2025-06-27 15:37:21,044:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-27 15:37:21,044:INFO:create_model() successfully completed......................................
2025-06-27 15:37:21,116:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:21,116:INFO:Creating metrics dataframe
2025-06-27 15:37:21,116:INFO:Initializing Linear Discriminant Analysis
2025-06-27 15:37:21,116:INFO:Total runtime is 0.20990229050318404 minutes
2025-06-27 15:37:21,116:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:21,116:INFO:Initializing create_model()
2025-06-27 15:37:21,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:21,116:INFO:Checking exceptions
2025-06-27 15:37:21,116:INFO:Importing libraries
2025-06-27 15:37:21,116:INFO:Copying training dataset
2025-06-27 15:37:21,121:INFO:Defining folds
2025-06-27 15:37:21,121:INFO:Declaring metric variables
2025-06-27 15:37:21,121:INFO:Importing untrained model
2025-06-27 15:37:21,121:INFO:Linear Discriminant Analysis Imported successfully
2025-06-27 15:37:21,123:INFO:Starting cross validation
2025-06-27 15:37:21,123:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:21,363:INFO:Calculating mean and std
2025-06-27 15:37:21,363:INFO:Creating metrics dataframe
2025-06-27 15:37:21,370:INFO:Uploading results into container
2025-06-27 15:37:21,370:INFO:Uploading model into container now
2025-06-27 15:37:21,370:INFO:_master_model_container: 11
2025-06-27 15:37:21,370:INFO:_display_container: 2
2025-06-27 15:37:21,370:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-27 15:37:21,370:INFO:create_model() successfully completed......................................
2025-06-27 15:37:21,460:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:21,460:INFO:Creating metrics dataframe
2025-06-27 15:37:21,460:INFO:Initializing Extra Trees Classifier
2025-06-27 15:37:21,460:INFO:Total runtime is 0.2156327605247498 minutes
2025-06-27 15:37:21,460:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:21,460:INFO:Initializing create_model()
2025-06-27 15:37:21,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:21,460:INFO:Checking exceptions
2025-06-27 15:37:21,460:INFO:Importing libraries
2025-06-27 15:37:21,460:INFO:Copying training dataset
2025-06-27 15:37:21,467:INFO:Defining folds
2025-06-27 15:37:21,467:INFO:Declaring metric variables
2025-06-27 15:37:21,467:INFO:Importing untrained model
2025-06-27 15:37:21,467:INFO:Extra Trees Classifier Imported successfully
2025-06-27 15:37:21,474:INFO:Starting cross validation
2025-06-27 15:37:21,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:22,465:INFO:Calculating mean and std
2025-06-27 15:37:22,465:INFO:Creating metrics dataframe
2025-06-27 15:37:22,465:INFO:Uploading results into container
2025-06-27 15:37:22,465:INFO:Uploading model into container now
2025-06-27 15:37:22,465:INFO:_master_model_container: 12
2025-06-27 15:37:22,465:INFO:_display_container: 2
2025-06-27 15:37:22,465:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-06-27 15:37:22,465:INFO:create_model() successfully completed......................................
2025-06-27 15:37:22,538:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:22,538:INFO:Creating metrics dataframe
2025-06-27 15:37:22,538:INFO:Initializing Light Gradient Boosting Machine
2025-06-27 15:37:22,538:INFO:Total runtime is 0.2335946122805278 minutes
2025-06-27 15:37:22,538:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:22,538:INFO:Initializing create_model()
2025-06-27 15:37:22,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:22,538:INFO:Checking exceptions
2025-06-27 15:37:22,538:INFO:Importing libraries
2025-06-27 15:37:22,538:INFO:Copying training dataset
2025-06-27 15:37:22,538:INFO:Defining folds
2025-06-27 15:37:22,538:INFO:Declaring metric variables
2025-06-27 15:37:22,538:INFO:Importing untrained model
2025-06-27 15:37:22,546:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-27 15:37:22,546:INFO:Starting cross validation
2025-06-27 15:37:22,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:25,757:INFO:Calculating mean and std
2025-06-27 15:37:25,758:INFO:Creating metrics dataframe
2025-06-27 15:37:25,762:INFO:Uploading results into container
2025-06-27 15:37:25,762:INFO:Uploading model into container now
2025-06-27 15:37:25,762:INFO:_master_model_container: 13
2025-06-27 15:37:25,762:INFO:_display_container: 2
2025-06-27 15:37:25,764:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-27 15:37:25,764:INFO:create_model() successfully completed......................................
2025-06-27 15:37:25,856:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:25,856:INFO:Creating metrics dataframe
2025-06-27 15:37:25,860:INFO:Initializing Dummy Classifier
2025-06-27 15:37:25,860:INFO:Total runtime is 0.2889619112014771 minutes
2025-06-27 15:37:25,860:INFO:SubProcess create_model() called ==================================
2025-06-27 15:37:25,860:INFO:Initializing create_model()
2025-06-27 15:37:25,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024A817C1510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:25,860:INFO:Checking exceptions
2025-06-27 15:37:25,860:INFO:Importing libraries
2025-06-27 15:37:25,860:INFO:Copying training dataset
2025-06-27 15:37:25,868:INFO:Defining folds
2025-06-27 15:37:25,868:INFO:Declaring metric variables
2025-06-27 15:37:25,868:INFO:Importing untrained model
2025-06-27 15:37:25,868:INFO:Dummy Classifier Imported successfully
2025-06-27 15:37:25,868:INFO:Starting cross validation
2025-06-27 15:37:25,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-27 15:37:26,017:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,022:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,028:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,034:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,039:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,039:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,043:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,051:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,051:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,055:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-27 15:37:26,079:INFO:Calculating mean and std
2025-06-27 15:37:26,080:INFO:Creating metrics dataframe
2025-06-27 15:37:26,080:INFO:Uploading results into container
2025-06-27 15:37:26,080:INFO:Uploading model into container now
2025-06-27 15:37:26,080:INFO:_master_model_container: 14
2025-06-27 15:37:26,080:INFO:_display_container: 2
2025-06-27 15:37:26,080:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-06-27 15:37:26,080:INFO:create_model() successfully completed......................................
2025-06-27 15:37:26,156:INFO:SubProcess create_model() end ==================================
2025-06-27 15:37:26,156:INFO:Creating metrics dataframe
2025-06-27 15:37:26,156:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-06-27 15:37:26,162:INFO:Initializing create_model()
2025-06-27 15:37:26,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:26,162:INFO:Checking exceptions
2025-06-27 15:37:26,162:INFO:Importing libraries
2025-06-27 15:37:26,162:INFO:Copying training dataset
2025-06-27 15:37:26,168:INFO:Defining folds
2025-06-27 15:37:26,168:INFO:Declaring metric variables
2025-06-27 15:37:26,168:INFO:Importing untrained model
2025-06-27 15:37:26,168:INFO:Declaring custom model
2025-06-27 15:37:26,168:INFO:Ridge Classifier Imported successfully
2025-06-27 15:37:26,171:INFO:Cross validation set to False
2025-06-27 15:37:26,171:INFO:Fitting Model
2025-06-27 15:37:26,202:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-06-27 15:37:26,202:INFO:create_model() successfully completed......................................
2025-06-27 15:37:26,264:INFO:Initializing create_model()
2025-06-27 15:37:26,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:26,264:INFO:Checking exceptions
2025-06-27 15:37:26,268:INFO:Importing libraries
2025-06-27 15:37:26,268:INFO:Copying training dataset
2025-06-27 15:37:26,268:INFO:Defining folds
2025-06-27 15:37:26,268:INFO:Declaring metric variables
2025-06-27 15:37:26,268:INFO:Importing untrained model
2025-06-27 15:37:26,268:INFO:Declaring custom model
2025-06-27 15:37:26,268:INFO:Linear Discriminant Analysis Imported successfully
2025-06-27 15:37:26,268:INFO:Cross validation set to False
2025-06-27 15:37:26,268:INFO:Fitting Model
2025-06-27 15:37:26,298:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-27 15:37:26,298:INFO:create_model() successfully completed......................................
2025-06-27 15:37:26,369:INFO:Initializing create_model()
2025-06-27 15:37:26,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:26,369:INFO:Checking exceptions
2025-06-27 15:37:26,369:INFO:Importing libraries
2025-06-27 15:37:26,369:INFO:Copying training dataset
2025-06-27 15:37:26,369:INFO:Defining folds
2025-06-27 15:37:26,369:INFO:Declaring metric variables
2025-06-27 15:37:26,369:INFO:Importing untrained model
2025-06-27 15:37:26,369:INFO:Declaring custom model
2025-06-27 15:37:26,369:INFO:Logistic Regression Imported successfully
2025-06-27 15:37:26,369:INFO:Cross validation set to False
2025-06-27 15:37:26,369:INFO:Fitting Model
2025-06-27 15:37:26,486:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-27 15:37:26,486:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-27 15:37:26,486:INFO:create_model() successfully completed......................................
2025-06-27 15:37:26,547:INFO:Initializing create_model()
2025-06-27 15:37:26,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:26,547:INFO:Checking exceptions
2025-06-27 15:37:26,549:INFO:Importing libraries
2025-06-27 15:37:26,549:INFO:Copying training dataset
2025-06-27 15:37:26,551:INFO:Defining folds
2025-06-27 15:37:26,551:INFO:Declaring metric variables
2025-06-27 15:37:26,551:INFO:Importing untrained model
2025-06-27 15:37:26,551:INFO:Declaring custom model
2025-06-27 15:37:26,551:INFO:Random Forest Classifier Imported successfully
2025-06-27 15:37:26,554:INFO:Cross validation set to False
2025-06-27 15:37:26,554:INFO:Fitting Model
2025-06-27 15:37:26,740:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-06-27 15:37:26,740:INFO:create_model() successfully completed......................................
2025-06-27 15:37:26,796:INFO:Initializing create_model()
2025-06-27 15:37:26,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024A812ABA90>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-27 15:37:26,796:INFO:Checking exceptions
2025-06-27 15:37:26,796:INFO:Importing libraries
2025-06-27 15:37:26,796:INFO:Copying training dataset
2025-06-27 15:37:26,796:INFO:Defining folds
2025-06-27 15:37:26,796:INFO:Declaring metric variables
2025-06-27 15:37:26,796:INFO:Importing untrained model
2025-06-27 15:37:26,796:INFO:Declaring custom model
2025-06-27 15:37:26,796:INFO:Ada Boost Classifier Imported successfully
2025-06-27 15:37:26,796:INFO:Cross validation set to False
2025-06-27 15:37:26,796:INFO:Fitting Model
2025-06-27 15:37:26,833:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-27 15:37:26,887:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-06-27 15:37:26,887:INFO:create_model() successfully completed......................................
2025-06-27 15:37:26,981:INFO:_master_model_container: 14
2025-06-27 15:37:26,981:INFO:_display_container: 2
2025-06-27 15:37:26,982:INFO:[RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)]
2025-06-27 15:37:26,982:INFO:compare_models() successfully completed......................................
2025-07-01 12:36:09,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 12:36:09,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 12:36:09,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 12:36:09,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 12:42:15,924:INFO:PyCaret ClassificationExperiment
2025-07-01 12:42:15,925:INFO:Logging name: clf-default-name
2025-07-01 12:42:15,925:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-01 12:42:15,926:INFO:version 3.3.2
2025-07-01 12:42:15,926:INFO:Initializing setup()
2025-07-01 12:42:15,926:INFO:self.USI: 12af
2025-07-01 12:42:15,926:INFO:self._variable_keys: {'idx', 'y_train', 'fold_groups_param', 'fix_imbalance', 'fold_shuffle_param', 'target_param', 'pipeline', '_ml_usecase', 'y_test', 'memory', 'is_multiclass', 'X_train', 'USI', 'fold_generator', 'html_param', 'logging_param', 'gpu_param', 'X_test', 'seed', 'log_plots_param', '_available_plots', 'gpu_n_jobs_param', 'data', 'y', 'X', 'exp_id', 'n_jobs_param', 'exp_name_log'}
2025-07-01 12:42:15,926:INFO:Checking environment
2025-07-01 12:42:15,926:INFO:python_version: 3.10.4
2025-07-01 12:42:15,926:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-07-01 12:42:15,926:INFO:machine: AMD64
2025-07-01 12:42:15,993:INFO:platform: Windows-10-10.0.26100-SP0
2025-07-01 12:42:16,022:INFO:Memory: svmem(total=16871448576, available=1007796224, percent=94.0, used=15863652352, free=1007796224)
2025-07-01 12:42:16,022:INFO:Physical Core: 10
2025-07-01 12:42:16,023:INFO:Logical Core: 12
2025-07-01 12:42:16,023:INFO:Checking libraries
2025-07-01 12:42:16,023:INFO:System:
2025-07-01 12:42:16,023:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-07-01 12:42:16,023:INFO:executable: C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\Scripts\python.exe
2025-07-01 12:42:16,023:INFO:   machine: Windows-10-10.0.26100-SP0
2025-07-01 12:42:16,023:INFO:PyCaret required dependencies:
2025-07-01 12:42:16,354:INFO:                 pip: 22.0.4
2025-07-01 12:42:16,354:INFO:          setuptools: 58.1.0
2025-07-01 12:42:16,354:INFO:             pycaret: 3.3.2
2025-07-01 12:42:16,354:INFO:             IPython: 8.37.0
2025-07-01 12:42:16,354:INFO:          ipywidgets: 8.1.7
2025-07-01 12:42:16,355:INFO:                tqdm: 4.67.1
2025-07-01 12:42:16,355:INFO:               numpy: 1.26.4
2025-07-01 12:42:16,355:INFO:              pandas: 2.1.4
2025-07-01 12:42:16,355:INFO:              jinja2: 3.1.6
2025-07-01 12:42:16,355:INFO:               scipy: 1.11.4
2025-07-01 12:42:16,355:INFO:              joblib: 1.3.2
2025-07-01 12:42:16,355:INFO:             sklearn: 1.4.2
2025-07-01 12:42:16,355:INFO:                pyod: 2.0.5
2025-07-01 12:42:16,355:INFO:            imblearn: 0.13.0
2025-07-01 12:42:16,355:INFO:   category_encoders: 2.7.0
2025-07-01 12:42:16,355:INFO:            lightgbm: 4.6.0
2025-07-01 12:42:16,355:INFO:               numba: 0.61.2
2025-07-01 12:42:16,355:INFO:            requests: 2.32.4
2025-07-01 12:42:16,355:INFO:          matplotlib: 3.7.5
2025-07-01 12:42:16,355:INFO:          scikitplot: 0.3.7
2025-07-01 12:42:16,356:INFO:         yellowbrick: 1.5
2025-07-01 12:42:16,356:INFO:              plotly: 5.24.1
2025-07-01 12:42:16,356:INFO:    plotly-resampler: Not installed
2025-07-01 12:42:16,356:INFO:             kaleido: 1.0.0
2025-07-01 12:42:16,356:INFO:           schemdraw: 0.15
2025-07-01 12:42:16,356:INFO:         statsmodels: 0.14.4
2025-07-01 12:42:16,356:INFO:              sktime: 0.26.0
2025-07-01 12:42:16,356:INFO:               tbats: 1.1.3
2025-07-01 12:42:16,357:INFO:            pmdarima: 2.0.4
2025-07-01 12:42:16,357:INFO:              psutil: 7.0.0
2025-07-01 12:42:16,357:INFO:          markupsafe: 3.0.2
2025-07-01 12:42:16,357:INFO:             pickle5: Not installed
2025-07-01 12:42:16,357:INFO:         cloudpickle: 3.1.1
2025-07-01 12:42:16,357:INFO:         deprecation: 2.1.0
2025-07-01 12:42:16,357:INFO:              xxhash: 3.5.0
2025-07-01 12:42:16,357:INFO:           wurlitzer: Not installed
2025-07-01 12:42:16,357:INFO:PyCaret optional dependencies:
2025-07-01 12:42:16,380:INFO:                shap: Not installed
2025-07-01 12:42:16,380:INFO:           interpret: Not installed
2025-07-01 12:42:16,380:INFO:                umap: Not installed
2025-07-01 12:42:16,381:INFO:     ydata_profiling: Not installed
2025-07-01 12:42:16,381:INFO:  explainerdashboard: Not installed
2025-07-01 12:42:16,381:INFO:             autoviz: Not installed
2025-07-01 12:42:16,381:INFO:           fairlearn: Not installed
2025-07-01 12:42:16,381:INFO:          deepchecks: Not installed
2025-07-01 12:42:16,381:INFO:             xgboost: Not installed
2025-07-01 12:42:16,381:INFO:            catboost: Not installed
2025-07-01 12:42:16,381:INFO:              kmodes: Not installed
2025-07-01 12:42:16,381:INFO:             mlxtend: Not installed
2025-07-01 12:42:16,381:INFO:       statsforecast: Not installed
2025-07-01 12:42:16,381:INFO:        tune_sklearn: Not installed
2025-07-01 12:42:16,381:INFO:                 ray: Not installed
2025-07-01 12:42:16,381:INFO:            hyperopt: Not installed
2025-07-01 12:42:16,381:INFO:              optuna: Not installed
2025-07-01 12:42:16,381:INFO:               skopt: Not installed
2025-07-01 12:42:16,381:INFO:              mlflow: Not installed
2025-07-01 12:42:16,381:INFO:              gradio: Not installed
2025-07-01 12:42:16,381:INFO:             fastapi: 0.115.14
2025-07-01 12:42:16,381:INFO:             uvicorn: 0.34.3
2025-07-01 12:42:16,381:INFO:              m2cgen: Not installed
2025-07-01 12:42:16,381:INFO:           evidently: Not installed
2025-07-01 12:42:16,381:INFO:               fugue: Not installed
2025-07-01 12:42:16,381:INFO:           streamlit: Not installed
2025-07-01 12:42:16,381:INFO:             prophet: Not installed
2025-07-01 12:42:16,381:INFO:None
2025-07-01 12:42:16,381:INFO:Set up data.
2025-07-01 12:42:16,401:INFO:Set up folding strategy.
2025-07-01 12:42:16,401:INFO:Set up train/test split.
2025-07-01 12:42:16,507:INFO:Set up index.
2025-07-01 12:42:16,509:INFO:Assigning column types.
2025-07-01 12:42:16,514:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-01 12:42:16,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 12:42:16,615:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:42:16,685:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:16,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:16,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 12:42:16,744:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:42:16,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:16,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:16,795:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-01 12:42:16,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:42:16,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:16,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:16,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:42:17,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,062:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-01 12:42:17,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,292:INFO:Preparing preprocessing pipeline...
2025-07-01 12:42:17,294:INFO:Set up simple imputation.
2025-07-01 12:42:17,299:INFO:Set up encoding of categorical features.
2025-07-01 12:42:17,374:INFO:Finished creating preprocessing pipeline.
2025-07-01 12:42:17,384:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-01 12:42:17,384:INFO:Creating final display dataframe.
2025-07-01 12:42:17,547:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape         (768, 10)
4        Transformed data shape         (768, 14)
5   Transformed train set shape         (537, 14)
6    Transformed test set shape         (231, 14)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              12af
2025-07-01 12:42:17,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:42:17,774:INFO:setup() successfully completed in 1.87s...............
2025-07-01 12:42:17,774:INFO:Initializing compare_models()
2025-07-01 12:42:17,774:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-07-01 12:42:17,774:INFO:Checking exceptions
2025-07-01 12:42:17,779:INFO:Preparing display monitor
2025-07-01 12:42:17,787:INFO:Initializing Logistic Regression
2025-07-01 12:42:17,787:INFO:Total runtime is 8.527437845865885e-06 minutes
2025-07-01 12:42:17,787:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:17,787:INFO:Initializing create_model()
2025-07-01 12:42:17,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:17,787:INFO:Checking exceptions
2025-07-01 12:42:17,787:INFO:Importing libraries
2025-07-01 12:42:17,787:INFO:Copying training dataset
2025-07-01 12:42:17,791:INFO:Defining folds
2025-07-01 12:42:17,791:INFO:Declaring metric variables
2025-07-01 12:42:17,791:INFO:Importing untrained model
2025-07-01 12:42:17,791:INFO:Logistic Regression Imported successfully
2025-07-01 12:42:17,791:INFO:Starting cross validation
2025-07-01 12:42:17,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:27,806:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:29,002:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:29,499:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:29,553:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:29,671:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:29,832:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:29,862:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:30,072:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:30,699:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:30,816:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:30,871:INFO:Calculating mean and std
2025-07-01 12:42:30,877:INFO:Creating metrics dataframe
2025-07-01 12:42:30,881:INFO:Uploading results into container
2025-07-01 12:42:30,882:INFO:Uploading model into container now
2025-07-01 12:42:30,882:INFO:_master_model_container: 1
2025-07-01 12:42:30,883:INFO:_display_container: 2
2025-07-01 12:42:30,883:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-01 12:42:30,883:INFO:create_model() successfully completed......................................
2025-07-01 12:42:31,005:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:31,006:INFO:Creating metrics dataframe
2025-07-01 12:42:31,010:INFO:Initializing K Neighbors Classifier
2025-07-01 12:42:31,010:INFO:Total runtime is 0.22039825121561687 minutes
2025-07-01 12:42:31,010:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:31,011:INFO:Initializing create_model()
2025-07-01 12:42:31,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:31,011:INFO:Checking exceptions
2025-07-01 12:42:31,011:INFO:Importing libraries
2025-07-01 12:42:31,011:INFO:Copying training dataset
2025-07-01 12:42:31,018:INFO:Defining folds
2025-07-01 12:42:31,018:INFO:Declaring metric variables
2025-07-01 12:42:31,019:INFO:Importing untrained model
2025-07-01 12:42:31,020:INFO:K Neighbors Classifier Imported successfully
2025-07-01 12:42:31,020:INFO:Starting cross validation
2025-07-01 12:42:31,022:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:37,125:INFO:Calculating mean and std
2025-07-01 12:42:37,128:INFO:Creating metrics dataframe
2025-07-01 12:42:37,134:INFO:Uploading results into container
2025-07-01 12:42:37,135:INFO:Uploading model into container now
2025-07-01 12:42:37,136:INFO:_master_model_container: 2
2025-07-01 12:42:37,136:INFO:_display_container: 2
2025-07-01 12:42:37,137:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-01 12:42:37,137:INFO:create_model() successfully completed......................................
2025-07-01 12:42:37,287:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:37,288:INFO:Creating metrics dataframe
2025-07-01 12:42:37,293:INFO:Initializing Naive Bayes
2025-07-01 12:42:37,293:INFO:Total runtime is 0.3251129587491354 minutes
2025-07-01 12:42:37,293:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:37,294:INFO:Initializing create_model()
2025-07-01 12:42:37,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:37,294:INFO:Checking exceptions
2025-07-01 12:42:37,294:INFO:Importing libraries
2025-07-01 12:42:37,294:INFO:Copying training dataset
2025-07-01 12:42:37,307:INFO:Defining folds
2025-07-01 12:42:37,307:INFO:Declaring metric variables
2025-07-01 12:42:37,307:INFO:Importing untrained model
2025-07-01 12:42:37,309:INFO:Naive Bayes Imported successfully
2025-07-01 12:42:37,309:INFO:Starting cross validation
2025-07-01 12:42:37,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:37,887:INFO:Calculating mean and std
2025-07-01 12:42:37,888:INFO:Creating metrics dataframe
2025-07-01 12:42:37,892:INFO:Uploading results into container
2025-07-01 12:42:37,895:INFO:Uploading model into container now
2025-07-01 12:42:37,898:INFO:_master_model_container: 3
2025-07-01 12:42:37,899:INFO:_display_container: 2
2025-07-01 12:42:37,900:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-01 12:42:37,901:INFO:create_model() successfully completed......................................
2025-07-01 12:42:38,062:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:38,063:INFO:Creating metrics dataframe
2025-07-01 12:42:38,067:INFO:Initializing Decision Tree Classifier
2025-07-01 12:42:38,067:INFO:Total runtime is 0.338007652759552 minutes
2025-07-01 12:42:38,067:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:38,068:INFO:Initializing create_model()
2025-07-01 12:42:38,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:38,068:INFO:Checking exceptions
2025-07-01 12:42:38,068:INFO:Importing libraries
2025-07-01 12:42:38,068:INFO:Copying training dataset
2025-07-01 12:42:38,104:INFO:Defining folds
2025-07-01 12:42:38,105:INFO:Declaring metric variables
2025-07-01 12:42:38,106:INFO:Importing untrained model
2025-07-01 12:42:38,110:INFO:Decision Tree Classifier Imported successfully
2025-07-01 12:42:38,111:INFO:Starting cross validation
2025-07-01 12:42:38,113:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:38,668:INFO:Calculating mean and std
2025-07-01 12:42:38,669:INFO:Creating metrics dataframe
2025-07-01 12:42:38,671:INFO:Uploading results into container
2025-07-01 12:42:38,672:INFO:Uploading model into container now
2025-07-01 12:42:38,673:INFO:_master_model_container: 4
2025-07-01 12:42:38,673:INFO:_display_container: 2
2025-07-01 12:42:38,673:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-01 12:42:38,673:INFO:create_model() successfully completed......................................
2025-07-01 12:42:38,767:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:38,768:INFO:Creating metrics dataframe
2025-07-01 12:42:38,770:INFO:Initializing SVM - Linear Kernel
2025-07-01 12:42:38,770:INFO:Total runtime is 0.3497369885444641 minutes
2025-07-01 12:42:38,772:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:38,772:INFO:Initializing create_model()
2025-07-01 12:42:38,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:38,772:INFO:Checking exceptions
2025-07-01 12:42:38,772:INFO:Importing libraries
2025-07-01 12:42:38,772:INFO:Copying training dataset
2025-07-01 12:42:38,780:INFO:Defining folds
2025-07-01 12:42:38,780:INFO:Declaring metric variables
2025-07-01 12:42:38,780:INFO:Importing untrained model
2025-07-01 12:42:38,783:INFO:SVM - Linear Kernel Imported successfully
2025-07-01 12:42:38,786:INFO:Starting cross validation
2025-07-01 12:42:38,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:39,028:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:39,229:INFO:Calculating mean and std
2025-07-01 12:42:39,230:INFO:Creating metrics dataframe
2025-07-01 12:42:39,234:INFO:Uploading results into container
2025-07-01 12:42:39,234:INFO:Uploading model into container now
2025-07-01 12:42:39,235:INFO:_master_model_container: 5
2025-07-01 12:42:39,235:INFO:_display_container: 2
2025-07-01 12:42:39,235:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-01 12:42:39,235:INFO:create_model() successfully completed......................................
2025-07-01 12:42:39,352:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:39,352:INFO:Creating metrics dataframe
2025-07-01 12:42:39,357:INFO:Initializing Ridge Classifier
2025-07-01 12:42:39,357:INFO:Total runtime is 0.35951027075449626 minutes
2025-07-01 12:42:39,357:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:39,357:INFO:Initializing create_model()
2025-07-01 12:42:39,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:39,357:INFO:Checking exceptions
2025-07-01 12:42:39,357:INFO:Importing libraries
2025-07-01 12:42:39,357:INFO:Copying training dataset
2025-07-01 12:42:39,364:INFO:Defining folds
2025-07-01 12:42:39,364:INFO:Declaring metric variables
2025-07-01 12:42:39,366:INFO:Importing untrained model
2025-07-01 12:42:39,367:INFO:Ridge Classifier Imported successfully
2025-07-01 12:42:39,369:INFO:Starting cross validation
2025-07-01 12:42:39,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:39,774:INFO:Calculating mean and std
2025-07-01 12:42:39,775:INFO:Creating metrics dataframe
2025-07-01 12:42:39,779:INFO:Uploading results into container
2025-07-01 12:42:39,779:INFO:Uploading model into container now
2025-07-01 12:42:39,780:INFO:_master_model_container: 6
2025-07-01 12:42:39,780:INFO:_display_container: 2
2025-07-01 12:42:39,780:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-01 12:42:39,781:INFO:create_model() successfully completed......................................
2025-07-01 12:42:39,899:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:39,899:INFO:Creating metrics dataframe
2025-07-01 12:42:39,904:INFO:Initializing Random Forest Classifier
2025-07-01 12:42:39,904:INFO:Total runtime is 0.368634565671285 minutes
2025-07-01 12:42:39,905:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:39,905:INFO:Initializing create_model()
2025-07-01 12:42:39,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:39,905:INFO:Checking exceptions
2025-07-01 12:42:39,905:INFO:Importing libraries
2025-07-01 12:42:39,905:INFO:Copying training dataset
2025-07-01 12:42:39,912:INFO:Defining folds
2025-07-01 12:42:39,913:INFO:Declaring metric variables
2025-07-01 12:42:39,913:INFO:Importing untrained model
2025-07-01 12:42:39,913:INFO:Random Forest Classifier Imported successfully
2025-07-01 12:42:39,914:INFO:Starting cross validation
2025-07-01 12:42:39,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:42,121:INFO:Calculating mean and std
2025-07-01 12:42:42,123:INFO:Creating metrics dataframe
2025-07-01 12:42:42,126:INFO:Uploading results into container
2025-07-01 12:42:42,127:INFO:Uploading model into container now
2025-07-01 12:42:42,128:INFO:_master_model_container: 7
2025-07-01 12:42:42,128:INFO:_display_container: 2
2025-07-01 12:42:42,128:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-01 12:42:42,129:INFO:create_model() successfully completed......................................
2025-07-01 12:42:42,242:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:42,243:INFO:Creating metrics dataframe
2025-07-01 12:42:42,256:INFO:Initializing Quadratic Discriminant Analysis
2025-07-01 12:42:42,256:INFO:Total runtime is 0.40782811244328815 minutes
2025-07-01 12:42:42,257:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:42,258:INFO:Initializing create_model()
2025-07-01 12:42:42,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:42,259:INFO:Checking exceptions
2025-07-01 12:42:42,259:INFO:Importing libraries
2025-07-01 12:42:42,261:INFO:Copying training dataset
2025-07-01 12:42:42,286:INFO:Defining folds
2025-07-01 12:42:42,286:INFO:Declaring metric variables
2025-07-01 12:42:42,286:INFO:Importing untrained model
2025-07-01 12:42:42,287:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-01 12:42:42,287:INFO:Starting cross validation
2025-07-01 12:42:42,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:42,483:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,487:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,490:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,490:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,497:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,510:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,540:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,625:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,640:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 12:42:42,747:INFO:Calculating mean and std
2025-07-01 12:42:42,748:INFO:Creating metrics dataframe
2025-07-01 12:42:42,752:INFO:Uploading results into container
2025-07-01 12:42:42,752:INFO:Uploading model into container now
2025-07-01 12:42:42,753:INFO:_master_model_container: 8
2025-07-01 12:42:42,753:INFO:_display_container: 2
2025-07-01 12:42:42,753:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-01 12:42:42,753:INFO:create_model() successfully completed......................................
2025-07-01 12:42:42,859:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:42,859:INFO:Creating metrics dataframe
2025-07-01 12:42:42,864:INFO:Initializing Ada Boost Classifier
2025-07-01 12:42:42,864:INFO:Total runtime is 0.4179636081059774 minutes
2025-07-01 12:42:42,864:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:42,864:INFO:Initializing create_model()
2025-07-01 12:42:42,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:42,864:INFO:Checking exceptions
2025-07-01 12:42:42,864:INFO:Importing libraries
2025-07-01 12:42:42,865:INFO:Copying training dataset
2025-07-01 12:42:42,869:INFO:Defining folds
2025-07-01 12:42:42,869:INFO:Declaring metric variables
2025-07-01 12:42:42,870:INFO:Importing untrained model
2025-07-01 12:42:42,871:INFO:Ada Boost Classifier Imported successfully
2025-07-01 12:42:42,872:INFO:Starting cross validation
2025-07-01 12:42:42,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:43,025:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,027:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,031:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,070:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,074:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,097:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,228:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,228:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,262:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:43,917:INFO:Calculating mean and std
2025-07-01 12:42:43,919:INFO:Creating metrics dataframe
2025-07-01 12:42:43,923:INFO:Uploading results into container
2025-07-01 12:42:43,923:INFO:Uploading model into container now
2025-07-01 12:42:43,924:INFO:_master_model_container: 9
2025-07-01 12:42:43,924:INFO:_display_container: 2
2025-07-01 12:42:43,924:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-01 12:42:43,924:INFO:create_model() successfully completed......................................
2025-07-01 12:42:44,030:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:44,030:INFO:Creating metrics dataframe
2025-07-01 12:42:44,033:INFO:Initializing Gradient Boosting Classifier
2025-07-01 12:42:44,033:INFO:Total runtime is 0.43745376269022623 minutes
2025-07-01 12:42:44,034:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:44,034:INFO:Initializing create_model()
2025-07-01 12:42:44,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:44,034:INFO:Checking exceptions
2025-07-01 12:42:44,034:INFO:Importing libraries
2025-07-01 12:42:44,034:INFO:Copying training dataset
2025-07-01 12:42:44,039:INFO:Defining folds
2025-07-01 12:42:44,039:INFO:Declaring metric variables
2025-07-01 12:42:44,040:INFO:Importing untrained model
2025-07-01 12:42:44,043:INFO:Gradient Boosting Classifier Imported successfully
2025-07-01 12:42:44,044:INFO:Starting cross validation
2025-07-01 12:42:44,049:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:45,482:INFO:Calculating mean and std
2025-07-01 12:42:45,484:INFO:Creating metrics dataframe
2025-07-01 12:42:45,487:INFO:Uploading results into container
2025-07-01 12:42:45,488:INFO:Uploading model into container now
2025-07-01 12:42:45,488:INFO:_master_model_container: 10
2025-07-01 12:42:45,488:INFO:_display_container: 2
2025-07-01 12:42:45,489:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-01 12:42:45,489:INFO:create_model() successfully completed......................................
2025-07-01 12:42:45,595:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:45,595:INFO:Creating metrics dataframe
2025-07-01 12:42:45,599:INFO:Initializing Linear Discriminant Analysis
2025-07-01 12:42:45,599:INFO:Total runtime is 0.46355374256769816 minutes
2025-07-01 12:42:45,599:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:45,600:INFO:Initializing create_model()
2025-07-01 12:42:45,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:45,600:INFO:Checking exceptions
2025-07-01 12:42:45,600:INFO:Importing libraries
2025-07-01 12:42:45,600:INFO:Copying training dataset
2025-07-01 12:42:45,604:INFO:Defining folds
2025-07-01 12:42:45,605:INFO:Declaring metric variables
2025-07-01 12:42:45,607:INFO:Importing untrained model
2025-07-01 12:42:45,607:INFO:Linear Discriminant Analysis Imported successfully
2025-07-01 12:42:45,607:INFO:Starting cross validation
2025-07-01 12:42:45,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:45,993:INFO:Calculating mean and std
2025-07-01 12:42:45,995:INFO:Creating metrics dataframe
2025-07-01 12:42:45,999:INFO:Uploading results into container
2025-07-01 12:42:45,999:INFO:Uploading model into container now
2025-07-01 12:42:46,000:INFO:_master_model_container: 11
2025-07-01 12:42:46,000:INFO:_display_container: 2
2025-07-01 12:42:46,000:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-01 12:42:46,001:INFO:create_model() successfully completed......................................
2025-07-01 12:42:46,100:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:46,100:INFO:Creating metrics dataframe
2025-07-01 12:42:46,105:INFO:Initializing Extra Trees Classifier
2025-07-01 12:42:46,106:INFO:Total runtime is 0.47199192841847737 minutes
2025-07-01 12:42:46,106:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:46,106:INFO:Initializing create_model()
2025-07-01 12:42:46,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:46,107:INFO:Checking exceptions
2025-07-01 12:42:46,107:INFO:Importing libraries
2025-07-01 12:42:46,107:INFO:Copying training dataset
2025-07-01 12:42:46,112:INFO:Defining folds
2025-07-01 12:42:46,113:INFO:Declaring metric variables
2025-07-01 12:42:46,113:INFO:Importing untrained model
2025-07-01 12:42:46,115:INFO:Extra Trees Classifier Imported successfully
2025-07-01 12:42:46,119:INFO:Starting cross validation
2025-07-01 12:42:46,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:47,682:INFO:Calculating mean and std
2025-07-01 12:42:47,684:INFO:Creating metrics dataframe
2025-07-01 12:42:47,686:INFO:Uploading results into container
2025-07-01 12:42:47,688:INFO:Uploading model into container now
2025-07-01 12:42:47,690:INFO:_master_model_container: 12
2025-07-01 12:42:47,690:INFO:_display_container: 2
2025-07-01 12:42:47,691:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-01 12:42:47,691:INFO:create_model() successfully completed......................................
2025-07-01 12:42:47,807:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:47,807:INFO:Creating metrics dataframe
2025-07-01 12:42:47,818:INFO:Initializing Light Gradient Boosting Machine
2025-07-01 12:42:47,819:INFO:Total runtime is 0.500547460714976 minutes
2025-07-01 12:42:47,819:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:47,820:INFO:Initializing create_model()
2025-07-01 12:42:47,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:47,820:INFO:Checking exceptions
2025-07-01 12:42:47,820:INFO:Importing libraries
2025-07-01 12:42:47,820:INFO:Copying training dataset
2025-07-01 12:42:47,828:INFO:Defining folds
2025-07-01 12:42:47,828:INFO:Declaring metric variables
2025-07-01 12:42:47,828:INFO:Importing untrained model
2025-07-01 12:42:47,830:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-01 12:42:47,830:INFO:Starting cross validation
2025-07-01 12:42:47,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:55,169:INFO:Calculating mean and std
2025-07-01 12:42:55,170:INFO:Creating metrics dataframe
2025-07-01 12:42:55,173:INFO:Uploading results into container
2025-07-01 12:42:55,174:INFO:Uploading model into container now
2025-07-01 12:42:55,174:INFO:_master_model_container: 13
2025-07-01 12:42:55,174:INFO:_display_container: 2
2025-07-01 12:42:55,175:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-01 12:42:55,175:INFO:create_model() successfully completed......................................
2025-07-01 12:42:55,260:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:55,260:INFO:Creating metrics dataframe
2025-07-01 12:42:55,265:INFO:Initializing Dummy Classifier
2025-07-01 12:42:55,265:INFO:Total runtime is 0.6246524691581726 minutes
2025-07-01 12:42:55,265:INFO:SubProcess create_model() called ==================================
2025-07-01 12:42:55,265:INFO:Initializing create_model()
2025-07-01 12:42:55,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026EBC5E3FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:55,265:INFO:Checking exceptions
2025-07-01 12:42:55,265:INFO:Importing libraries
2025-07-01 12:42:55,265:INFO:Copying training dataset
2025-07-01 12:42:55,271:INFO:Defining folds
2025-07-01 12:42:55,273:INFO:Declaring metric variables
2025-07-01 12:42:55,274:INFO:Importing untrained model
2025-07-01 12:42:55,276:INFO:Dummy Classifier Imported successfully
2025-07-01 12:42:55,278:INFO:Starting cross validation
2025-07-01 12:42:55,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:42:55,458:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,460:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,475:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,475:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,495:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,537:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,587:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,609:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,617:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,664:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 12:42:55,682:INFO:Calculating mean and std
2025-07-01 12:42:55,684:INFO:Creating metrics dataframe
2025-07-01 12:42:55,694:INFO:Uploading results into container
2025-07-01 12:42:55,695:INFO:Uploading model into container now
2025-07-01 12:42:55,695:INFO:_master_model_container: 14
2025-07-01 12:42:55,695:INFO:_display_container: 2
2025-07-01 12:42:55,696:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-01 12:42:55,696:INFO:create_model() successfully completed......................................
2025-07-01 12:42:55,791:INFO:SubProcess create_model() end ==================================
2025-07-01 12:42:55,791:INFO:Creating metrics dataframe
2025-07-01 12:42:55,799:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-07-01 12:42:55,802:INFO:Initializing create_model()
2025-07-01 12:42:55,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:55,802:INFO:Checking exceptions
2025-07-01 12:42:55,804:INFO:Importing libraries
2025-07-01 12:42:55,804:INFO:Copying training dataset
2025-07-01 12:42:55,813:INFO:Defining folds
2025-07-01 12:42:55,813:INFO:Declaring metric variables
2025-07-01 12:42:55,813:INFO:Importing untrained model
2025-07-01 12:42:55,813:INFO:Declaring custom model
2025-07-01 12:42:55,815:INFO:Ridge Classifier Imported successfully
2025-07-01 12:42:55,817:INFO:Cross validation set to False
2025-07-01 12:42:55,817:INFO:Fitting Model
2025-07-01 12:42:55,895:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-01 12:42:55,895:INFO:create_model() successfully completed......................................
2025-07-01 12:42:56,005:INFO:Initializing create_model()
2025-07-01 12:42:56,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:56,005:INFO:Checking exceptions
2025-07-01 12:42:56,007:INFO:Importing libraries
2025-07-01 12:42:56,007:INFO:Copying training dataset
2025-07-01 12:42:56,019:INFO:Defining folds
2025-07-01 12:42:56,019:INFO:Declaring metric variables
2025-07-01 12:42:56,020:INFO:Importing untrained model
2025-07-01 12:42:56,020:INFO:Declaring custom model
2025-07-01 12:42:56,020:INFO:Linear Discriminant Analysis Imported successfully
2025-07-01 12:42:56,024:INFO:Cross validation set to False
2025-07-01 12:42:56,025:INFO:Fitting Model
2025-07-01 12:42:56,093:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-01 12:42:56,093:INFO:create_model() successfully completed......................................
2025-07-01 12:42:56,174:INFO:Initializing create_model()
2025-07-01 12:42:56,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:56,175:INFO:Checking exceptions
2025-07-01 12:42:56,175:INFO:Importing libraries
2025-07-01 12:42:56,175:INFO:Copying training dataset
2025-07-01 12:42:56,180:INFO:Defining folds
2025-07-01 12:42:56,180:INFO:Declaring metric variables
2025-07-01 12:42:56,182:INFO:Importing untrained model
2025-07-01 12:42:56,182:INFO:Declaring custom model
2025-07-01 12:42:56,183:INFO:Logistic Regression Imported successfully
2025-07-01 12:42:56,184:INFO:Cross validation set to False
2025-07-01 12:42:56,184:INFO:Fitting Model
2025-07-01 12:42:56,440:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:42:56,441:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-01 12:42:56,442:INFO:create_model() successfully completed......................................
2025-07-01 12:42:56,537:INFO:Initializing create_model()
2025-07-01 12:42:56,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:56,537:INFO:Checking exceptions
2025-07-01 12:42:56,540:INFO:Importing libraries
2025-07-01 12:42:56,540:INFO:Copying training dataset
2025-07-01 12:42:56,547:INFO:Defining folds
2025-07-01 12:42:56,547:INFO:Declaring metric variables
2025-07-01 12:42:56,547:INFO:Importing untrained model
2025-07-01 12:42:56,548:INFO:Declaring custom model
2025-07-01 12:42:56,548:INFO:Random Forest Classifier Imported successfully
2025-07-01 12:42:56,550:INFO:Cross validation set to False
2025-07-01 12:42:56,550:INFO:Fitting Model
2025-07-01 12:42:57,025:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-01 12:42:57,025:INFO:create_model() successfully completed......................................
2025-07-01 12:42:57,144:INFO:Initializing create_model()
2025-07-01 12:42:57,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:57,145:INFO:Checking exceptions
2025-07-01 12:42:57,147:INFO:Importing libraries
2025-07-01 12:42:57,147:INFO:Copying training dataset
2025-07-01 12:42:57,155:INFO:Defining folds
2025-07-01 12:42:57,155:INFO:Declaring metric variables
2025-07-01 12:42:57,155:INFO:Importing untrained model
2025-07-01 12:42:57,155:INFO:Declaring custom model
2025-07-01 12:42:57,157:INFO:Ada Boost Classifier Imported successfully
2025-07-01 12:42:57,158:INFO:Cross validation set to False
2025-07-01 12:42:57,159:INFO:Fitting Model
2025-07-01 12:42:57,237:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 12:42:57,393:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-01 12:42:57,394:INFO:create_model() successfully completed......................................
2025-07-01 12:42:57,479:INFO:Initializing create_model()
2025-07-01 12:42:57,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:57,479:INFO:Checking exceptions
2025-07-01 12:42:57,481:INFO:Importing libraries
2025-07-01 12:42:57,481:INFO:Copying training dataset
2025-07-01 12:42:57,486:INFO:Defining folds
2025-07-01 12:42:57,486:INFO:Declaring metric variables
2025-07-01 12:42:57,486:INFO:Importing untrained model
2025-07-01 12:42:57,486:INFO:Declaring custom model
2025-07-01 12:42:57,487:INFO:Gradient Boosting Classifier Imported successfully
2025-07-01 12:42:57,489:INFO:Cross validation set to False
2025-07-01 12:42:57,489:INFO:Fitting Model
2025-07-01 12:42:57,857:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-01 12:42:57,857:INFO:create_model() successfully completed......................................
2025-07-01 12:42:57,943:INFO:Initializing create_model()
2025-07-01 12:42:57,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:57,943:INFO:Checking exceptions
2025-07-01 12:42:57,944:INFO:Importing libraries
2025-07-01 12:42:57,944:INFO:Copying training dataset
2025-07-01 12:42:57,948:INFO:Defining folds
2025-07-01 12:42:57,948:INFO:Declaring metric variables
2025-07-01 12:42:57,948:INFO:Importing untrained model
2025-07-01 12:42:57,948:INFO:Declaring custom model
2025-07-01 12:42:57,949:INFO:Extra Trees Classifier Imported successfully
2025-07-01 12:42:57,950:INFO:Cross validation set to False
2025-07-01 12:42:57,950:INFO:Fitting Model
2025-07-01 12:42:58,272:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-01 12:42:58,272:INFO:create_model() successfully completed......................................
2025-07-01 12:42:58,390:INFO:Initializing create_model()
2025-07-01 12:42:58,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:58,391:INFO:Checking exceptions
2025-07-01 12:42:58,393:INFO:Importing libraries
2025-07-01 12:42:58,393:INFO:Copying training dataset
2025-07-01 12:42:58,398:INFO:Defining folds
2025-07-01 12:42:58,399:INFO:Declaring metric variables
2025-07-01 12:42:58,399:INFO:Importing untrained model
2025-07-01 12:42:58,399:INFO:Declaring custom model
2025-07-01 12:42:58,400:INFO:K Neighbors Classifier Imported successfully
2025-07-01 12:42:58,403:INFO:Cross validation set to False
2025-07-01 12:42:58,403:INFO:Fitting Model
2025-07-01 12:42:58,452:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-01 12:42:58,452:INFO:create_model() successfully completed......................................
2025-07-01 12:42:58,543:INFO:Initializing create_model()
2025-07-01 12:42:58,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:58,544:INFO:Checking exceptions
2025-07-01 12:42:58,545:INFO:Importing libraries
2025-07-01 12:42:58,545:INFO:Copying training dataset
2025-07-01 12:42:58,557:INFO:Defining folds
2025-07-01 12:42:58,557:INFO:Declaring metric variables
2025-07-01 12:42:58,557:INFO:Importing untrained model
2025-07-01 12:42:58,557:INFO:Declaring custom model
2025-07-01 12:42:58,559:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-01 12:42:58,561:INFO:Cross validation set to False
2025-07-01 12:42:58,561:INFO:Fitting Model
2025-07-01 12:42:58,606:INFO:[LightGBM] [Info] Number of positive: 187, number of negative: 350
2025-07-01 12:42:58,607:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.
2025-07-01 12:42:58,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-07-01 12:42:58,607:INFO:[LightGBM] [Info] Total Bins 622
2025-07-01 12:42:58,609:INFO:[LightGBM] [Info] Number of data points in the train set: 537, number of used features: 13
2025-07-01 12:42:58,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348231 -> initscore=-0.626825
2025-07-01 12:42:58,609:INFO:[LightGBM] [Info] Start training from score -0.626825
2025-07-01 12:42:58,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 12:42:58,943:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-01 12:42:58,943:INFO:create_model() successfully completed......................................
2025-07-01 12:42:59,059:INFO:Initializing create_model()
2025-07-01 12:42:59,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC2C0460>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:42:59,059:INFO:Checking exceptions
2025-07-01 12:42:59,061:INFO:Importing libraries
2025-07-01 12:42:59,062:INFO:Copying training dataset
2025-07-01 12:42:59,073:INFO:Defining folds
2025-07-01 12:42:59,073:INFO:Declaring metric variables
2025-07-01 12:42:59,074:INFO:Importing untrained model
2025-07-01 12:42:59,075:INFO:Declaring custom model
2025-07-01 12:42:59,077:INFO:Naive Bayes Imported successfully
2025-07-01 12:42:59,082:INFO:Cross validation set to False
2025-07-01 12:42:59,082:INFO:Fitting Model
2025-07-01 12:42:59,150:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-01 12:42:59,151:INFO:create_model() successfully completed......................................
2025-07-01 12:42:59,267:INFO:_master_model_container: 14
2025-07-01 12:42:59,267:INFO:_display_container: 2
2025-07-01 12:42:59,273:INFO:[RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-07-01 12:42:59,273:INFO:compare_models() successfully completed......................................
2025-07-01 12:43:00,447:INFO:PyCaret ClassificationExperiment
2025-07-01 12:43:00,447:INFO:Logging name: clf-default-name
2025-07-01 12:43:00,447:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-01 12:43:00,447:INFO:version 3.3.2
2025-07-01 12:43:00,447:INFO:Initializing setup()
2025-07-01 12:43:00,447:INFO:self.USI: 9f0b
2025-07-01 12:43:00,447:INFO:self._variable_keys: {'idx', 'y_train', 'fold_groups_param', 'fix_imbalance', 'fold_shuffle_param', 'target_param', 'pipeline', '_ml_usecase', 'y_test', 'memory', 'is_multiclass', 'X_train', 'USI', 'fold_generator', 'html_param', 'logging_param', 'gpu_param', 'X_test', 'seed', 'log_plots_param', '_available_plots', 'gpu_n_jobs_param', 'data', 'y', 'X', 'exp_id', 'n_jobs_param', 'exp_name_log'}
2025-07-01 12:43:00,447:INFO:Checking environment
2025-07-01 12:43:00,447:INFO:python_version: 3.10.4
2025-07-01 12:43:00,447:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-07-01 12:43:00,447:INFO:machine: AMD64
2025-07-01 12:43:00,447:INFO:platform: Windows-10-10.0.26100-SP0
2025-07-01 12:43:00,460:INFO:Memory: svmem(total=16871448576, available=1143324672, percent=93.2, used=15728123904, free=1143324672)
2025-07-01 12:43:00,460:INFO:Physical Core: 10
2025-07-01 12:43:00,460:INFO:Logical Core: 12
2025-07-01 12:43:00,460:INFO:Checking libraries
2025-07-01 12:43:00,460:INFO:System:
2025-07-01 12:43:00,460:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-07-01 12:43:00,460:INFO:executable: C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\Scripts\python.exe
2025-07-01 12:43:00,460:INFO:   machine: Windows-10-10.0.26100-SP0
2025-07-01 12:43:00,460:INFO:PyCaret required dependencies:
2025-07-01 12:43:00,460:INFO:                 pip: 22.0.4
2025-07-01 12:43:00,460:INFO:          setuptools: 58.1.0
2025-07-01 12:43:00,460:INFO:             pycaret: 3.3.2
2025-07-01 12:43:00,460:INFO:             IPython: 8.37.0
2025-07-01 12:43:00,460:INFO:          ipywidgets: 8.1.7
2025-07-01 12:43:00,460:INFO:                tqdm: 4.67.1
2025-07-01 12:43:00,460:INFO:               numpy: 1.26.4
2025-07-01 12:43:00,460:INFO:              pandas: 2.1.4
2025-07-01 12:43:00,460:INFO:              jinja2: 3.1.6
2025-07-01 12:43:00,460:INFO:               scipy: 1.11.4
2025-07-01 12:43:00,460:INFO:              joblib: 1.3.2
2025-07-01 12:43:00,460:INFO:             sklearn: 1.4.2
2025-07-01 12:43:00,461:INFO:                pyod: 2.0.5
2025-07-01 12:43:00,461:INFO:            imblearn: 0.13.0
2025-07-01 12:43:00,461:INFO:   category_encoders: 2.7.0
2025-07-01 12:43:00,461:INFO:            lightgbm: 4.6.0
2025-07-01 12:43:00,461:INFO:               numba: 0.61.2
2025-07-01 12:43:00,461:INFO:            requests: 2.32.4
2025-07-01 12:43:00,461:INFO:          matplotlib: 3.7.5
2025-07-01 12:43:00,461:INFO:          scikitplot: 0.3.7
2025-07-01 12:43:00,461:INFO:         yellowbrick: 1.5
2025-07-01 12:43:00,461:INFO:              plotly: 5.24.1
2025-07-01 12:43:00,461:INFO:    plotly-resampler: Not installed
2025-07-01 12:43:00,461:INFO:             kaleido: 1.0.0
2025-07-01 12:43:00,461:INFO:           schemdraw: 0.15
2025-07-01 12:43:00,461:INFO:         statsmodels: 0.14.4
2025-07-01 12:43:00,461:INFO:              sktime: 0.26.0
2025-07-01 12:43:00,461:INFO:               tbats: 1.1.3
2025-07-01 12:43:00,461:INFO:            pmdarima: 2.0.4
2025-07-01 12:43:00,461:INFO:              psutil: 7.0.0
2025-07-01 12:43:00,461:INFO:          markupsafe: 3.0.2
2025-07-01 12:43:00,461:INFO:             pickle5: Not installed
2025-07-01 12:43:00,461:INFO:         cloudpickle: 3.1.1
2025-07-01 12:43:00,461:INFO:         deprecation: 2.1.0
2025-07-01 12:43:00,461:INFO:              xxhash: 3.5.0
2025-07-01 12:43:00,461:INFO:           wurlitzer: Not installed
2025-07-01 12:43:00,461:INFO:PyCaret optional dependencies:
2025-07-01 12:43:00,461:INFO:                shap: Not installed
2025-07-01 12:43:00,461:INFO:           interpret: Not installed
2025-07-01 12:43:00,461:INFO:                umap: Not installed
2025-07-01 12:43:00,461:INFO:     ydata_profiling: Not installed
2025-07-01 12:43:00,461:INFO:  explainerdashboard: Not installed
2025-07-01 12:43:00,461:INFO:             autoviz: Not installed
2025-07-01 12:43:00,461:INFO:           fairlearn: Not installed
2025-07-01 12:43:00,461:INFO:          deepchecks: Not installed
2025-07-01 12:43:00,461:INFO:             xgboost: Not installed
2025-07-01 12:43:00,461:INFO:            catboost: Not installed
2025-07-01 12:43:00,461:INFO:              kmodes: Not installed
2025-07-01 12:43:00,461:INFO:             mlxtend: Not installed
2025-07-01 12:43:00,461:INFO:       statsforecast: Not installed
2025-07-01 12:43:00,461:INFO:        tune_sklearn: Not installed
2025-07-01 12:43:00,461:INFO:                 ray: Not installed
2025-07-01 12:43:00,461:INFO:            hyperopt: Not installed
2025-07-01 12:43:00,461:INFO:              optuna: Not installed
2025-07-01 12:43:00,461:INFO:               skopt: Not installed
2025-07-01 12:43:00,461:INFO:              mlflow: Not installed
2025-07-01 12:43:00,461:INFO:              gradio: Not installed
2025-07-01 12:43:00,461:INFO:             fastapi: 0.115.14
2025-07-01 12:43:00,461:INFO:             uvicorn: 0.34.3
2025-07-01 12:43:00,462:INFO:              m2cgen: Not installed
2025-07-01 12:43:00,462:INFO:           evidently: Not installed
2025-07-01 12:43:00,462:INFO:               fugue: Not installed
2025-07-01 12:43:00,462:INFO:           streamlit: Not installed
2025-07-01 12:43:00,462:INFO:             prophet: Not installed
2025-07-01 12:43:00,462:INFO:None
2025-07-01 12:43:00,462:INFO:Set up data.
2025-07-01 12:43:00,465:INFO:Set up folding strategy.
2025-07-01 12:43:00,465:INFO:Set up train/test split.
2025-07-01 12:43:00,469:INFO:Set up index.
2025-07-01 12:43:00,469:INFO:Assigning column types.
2025-07-01 12:43:00,472:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-01 12:43:00,504:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 12:43:00,504:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:00,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 12:43:00,583:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:00,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,651:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-01 12:43:00,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:00,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:00,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,833:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-01 12:43:00,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:00,964:INFO:Preparing preprocessing pipeline...
2025-07-01 12:43:00,965:INFO:Set up simple imputation.
2025-07-01 12:43:00,967:INFO:Set up encoding of categorical features.
2025-07-01 12:43:01,012:INFO:Finished creating preprocessing pipeline.
2025-07-01 12:43:01,017:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-01 12:43:01,018:INFO:Creating final display dataframe.
2025-07-01 12:43:01,197:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape         (768, 10)
4        Transformed data shape         (768, 14)
5   Transformed train set shape         (537, 14)
6    Transformed test set shape         (231, 14)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              9f0b
2025-07-01 12:43:01,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:01,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:01,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:01,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:01,338:INFO:setup() successfully completed in 0.89s...............
2025-07-01 12:43:01,338:INFO:Initializing create_model()
2025-07-01 12:43:01,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC4038E0>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:43:01,338:INFO:Checking exceptions
2025-07-01 12:43:01,339:INFO:Importing libraries
2025-07-01 12:43:01,340:INFO:Copying training dataset
2025-07-01 12:43:01,346:INFO:Defining folds
2025-07-01 12:43:01,346:INFO:Declaring metric variables
2025-07-01 12:43:01,346:INFO:Importing untrained model
2025-07-01 12:43:01,347:INFO:Ridge Classifier Imported successfully
2025-07-01 12:43:01,347:INFO:Starting cross validation
2025-07-01 12:43:01,347:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:43:01,561:INFO:Calculating mean and std
2025-07-01 12:43:01,562:INFO:Creating metrics dataframe
2025-07-01 12:43:01,565:INFO:Finalizing model
2025-07-01 12:43:01,627:INFO:Uploading results into container
2025-07-01 12:43:01,629:INFO:Uploading model into container now
2025-07-01 12:43:01,650:INFO:_master_model_container: 1
2025-07-01 12:43:01,651:INFO:_display_container: 2
2025-07-01 12:43:01,654:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-01 12:43:01,654:INFO:create_model() successfully completed......................................
2025-07-01 12:43:01,755:INFO:Initializing save_model()
2025-07-01 12:43:01,756:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), model_name=models/ridge, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-01 12:43:01,756:INFO:Adding model into prep_pipe
2025-07-01 12:43:01,763:INFO:models/ridge.pkl saved in current working directory
2025-07-01 12:43:01,771:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                (...
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2025-07-01 12:43:01,771:INFO:save_model() successfully completed......................................
2025-07-01 12:43:01,860:INFO:Initializing plot_model()
2025-07-01 12:43:01,860:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC4038E0>, system=True)
2025-07-01 12:43:01,860:INFO:Checking exceptions
2025-07-01 12:43:01,864:INFO:Preloading libraries
2025-07-01 12:43:01,864:INFO:Copying training dataset
2025-07-01 12:43:01,864:INFO:Plot type: confusion_matrix
2025-07-01 12:43:03,524:INFO:Fitting Model
2025-07-01 12:43:03,532:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2025-07-01 12:43:03,534:INFO:Scoring test/hold-out set
2025-07-01 12:43:06,777:INFO:Initializing plot_model()
2025-07-01 12:43:06,777:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC4038E0>, system=True)
2025-07-01 12:43:06,777:INFO:Checking exceptions
2025-07-01 12:43:06,778:INFO:Initializing plot_model()
2025-07-01 12:43:06,778:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC4038E0>, system=True)
2025-07-01 12:43:06,778:INFO:Checking exceptions
2025-07-01 12:43:06,780:INFO:Preloading libraries
2025-07-01 12:43:06,781:INFO:Copying training dataset
2025-07-01 12:43:06,781:INFO:Plot type: feature
2025-07-01 12:43:11,822:INFO:Visual Rendered Successfully
2025-07-01 12:43:11,911:INFO:plot_model() successfully completed......................................
2025-07-01 12:43:16,286:INFO:PyCaret ClassificationExperiment
2025-07-01 12:43:16,286:INFO:Logging name: clf-default-name
2025-07-01 12:43:16,286:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-01 12:43:16,286:INFO:version 3.3.2
2025-07-01 12:43:16,286:INFO:Initializing setup()
2025-07-01 12:43:16,286:INFO:self.USI: dd7b
2025-07-01 12:43:16,286:INFO:self._variable_keys: {'idx', 'y_train', 'fold_groups_param', 'fix_imbalance', 'fold_shuffle_param', 'target_param', 'pipeline', '_ml_usecase', 'y_test', 'memory', 'is_multiclass', 'X_train', 'USI', 'fold_generator', 'html_param', 'logging_param', 'gpu_param', 'X_test', 'seed', 'log_plots_param', '_available_plots', 'gpu_n_jobs_param', 'data', 'y', 'X', 'exp_id', 'n_jobs_param', 'exp_name_log'}
2025-07-01 12:43:16,286:INFO:Checking environment
2025-07-01 12:43:16,286:INFO:python_version: 3.10.4
2025-07-01 12:43:16,287:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-07-01 12:43:16,287:INFO:machine: AMD64
2025-07-01 12:43:16,287:INFO:platform: Windows-10-10.0.26100-SP0
2025-07-01 12:43:16,307:INFO:Memory: svmem(total=16871448576, available=1869217792, percent=88.9, used=15002230784, free=1869217792)
2025-07-01 12:43:16,307:INFO:Physical Core: 10
2025-07-01 12:43:16,307:INFO:Logical Core: 12
2025-07-01 12:43:16,307:INFO:Checking libraries
2025-07-01 12:43:16,307:INFO:System:
2025-07-01 12:43:16,308:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-07-01 12:43:16,308:INFO:executable: C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\Scripts\python.exe
2025-07-01 12:43:16,308:INFO:   machine: Windows-10-10.0.26100-SP0
2025-07-01 12:43:16,308:INFO:PyCaret required dependencies:
2025-07-01 12:43:16,308:INFO:                 pip: 22.0.4
2025-07-01 12:43:16,308:INFO:          setuptools: 58.1.0
2025-07-01 12:43:16,308:INFO:             pycaret: 3.3.2
2025-07-01 12:43:16,308:INFO:             IPython: 8.37.0
2025-07-01 12:43:16,308:INFO:          ipywidgets: 8.1.7
2025-07-01 12:43:16,308:INFO:                tqdm: 4.67.1
2025-07-01 12:43:16,308:INFO:               numpy: 1.26.4
2025-07-01 12:43:16,308:INFO:              pandas: 2.1.4
2025-07-01 12:43:16,308:INFO:              jinja2: 3.1.6
2025-07-01 12:43:16,308:INFO:               scipy: 1.11.4
2025-07-01 12:43:16,308:INFO:              joblib: 1.3.2
2025-07-01 12:43:16,308:INFO:             sklearn: 1.4.2
2025-07-01 12:43:16,308:INFO:                pyod: 2.0.5
2025-07-01 12:43:16,309:INFO:            imblearn: 0.13.0
2025-07-01 12:43:16,309:INFO:   category_encoders: 2.7.0
2025-07-01 12:43:16,309:INFO:            lightgbm: 4.6.0
2025-07-01 12:43:16,309:INFO:               numba: 0.61.2
2025-07-01 12:43:16,309:INFO:            requests: 2.32.4
2025-07-01 12:43:16,309:INFO:          matplotlib: 3.7.5
2025-07-01 12:43:16,309:INFO:          scikitplot: 0.3.7
2025-07-01 12:43:16,309:INFO:         yellowbrick: 1.5
2025-07-01 12:43:16,309:INFO:              plotly: 5.24.1
2025-07-01 12:43:16,309:INFO:    plotly-resampler: Not installed
2025-07-01 12:43:16,309:INFO:             kaleido: 1.0.0
2025-07-01 12:43:16,309:INFO:           schemdraw: 0.15
2025-07-01 12:43:16,309:INFO:         statsmodels: 0.14.4
2025-07-01 12:43:16,309:INFO:              sktime: 0.26.0
2025-07-01 12:43:16,309:INFO:               tbats: 1.1.3
2025-07-01 12:43:16,309:INFO:            pmdarima: 2.0.4
2025-07-01 12:43:16,309:INFO:              psutil: 7.0.0
2025-07-01 12:43:16,309:INFO:          markupsafe: 3.0.2
2025-07-01 12:43:16,309:INFO:             pickle5: Not installed
2025-07-01 12:43:16,309:INFO:         cloudpickle: 3.1.1
2025-07-01 12:43:16,309:INFO:         deprecation: 2.1.0
2025-07-01 12:43:16,309:INFO:              xxhash: 3.5.0
2025-07-01 12:43:16,309:INFO:           wurlitzer: Not installed
2025-07-01 12:43:16,309:INFO:PyCaret optional dependencies:
2025-07-01 12:43:16,310:INFO:                shap: Not installed
2025-07-01 12:43:16,310:INFO:           interpret: Not installed
2025-07-01 12:43:16,310:INFO:                umap: Not installed
2025-07-01 12:43:16,310:INFO:     ydata_profiling: Not installed
2025-07-01 12:43:16,310:INFO:  explainerdashboard: Not installed
2025-07-01 12:43:16,310:INFO:             autoviz: Not installed
2025-07-01 12:43:16,310:INFO:           fairlearn: Not installed
2025-07-01 12:43:16,310:INFO:          deepchecks: Not installed
2025-07-01 12:43:16,310:INFO:             xgboost: Not installed
2025-07-01 12:43:16,310:INFO:            catboost: Not installed
2025-07-01 12:43:16,310:INFO:              kmodes: Not installed
2025-07-01 12:43:16,310:INFO:             mlxtend: Not installed
2025-07-01 12:43:16,310:INFO:       statsforecast: Not installed
2025-07-01 12:43:16,310:INFO:        tune_sklearn: Not installed
2025-07-01 12:43:16,310:INFO:                 ray: Not installed
2025-07-01 12:43:16,310:INFO:            hyperopt: Not installed
2025-07-01 12:43:16,310:INFO:              optuna: Not installed
2025-07-01 12:43:16,310:INFO:               skopt: Not installed
2025-07-01 12:43:16,311:INFO:              mlflow: Not installed
2025-07-01 12:43:16,311:INFO:              gradio: Not installed
2025-07-01 12:43:16,311:INFO:             fastapi: 0.115.14
2025-07-01 12:43:16,312:INFO:             uvicorn: 0.34.3
2025-07-01 12:43:16,313:INFO:              m2cgen: Not installed
2025-07-01 12:43:16,313:INFO:           evidently: Not installed
2025-07-01 12:43:16,314:INFO:               fugue: Not installed
2025-07-01 12:43:16,315:INFO:           streamlit: Not installed
2025-07-01 12:43:16,315:INFO:             prophet: Not installed
2025-07-01 12:43:16,315:INFO:None
2025-07-01 12:43:16,315:INFO:Set up data.
2025-07-01 12:43:16,325:INFO:Set up folding strategy.
2025-07-01 12:43:16,325:INFO:Set up train/test split.
2025-07-01 12:43:16,334:INFO:Set up index.
2025-07-01 12:43:16,334:INFO:Assigning column types.
2025-07-01 12:43:16,337:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-01 12:43:16,366:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 12:43:16,367:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:16,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 12:43:16,415:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:16,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,432:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-01 12:43:16,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:16,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,505:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 12:43:16,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,525:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-01 12:43:16,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,618:INFO:Preparing preprocessing pipeline...
2025-07-01 12:43:16,619:INFO:Set up simple imputation.
2025-07-01 12:43:16,620:INFO:Set up encoding of categorical features.
2025-07-01 12:43:16,646:INFO:Finished creating preprocessing pipeline.
2025-07-01 12:43:16,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-01 12:43:16,649:INFO:Creating final display dataframe.
2025-07-01 12:43:16,754:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape         (768, 10)
4        Transformed data shape         (768, 14)
5   Transformed train set shape         (537, 14)
6    Transformed test set shape         (231, 14)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              dd7b
2025-07-01 12:43:16,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:16,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:17,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:17,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 12:43:17,296:INFO:setup() successfully completed in 1.01s...............
2025-07-01 12:43:17,297:INFO:Initializing create_model()
2025-07-01 12:43:17,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC7DD5A0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 12:43:17,297:INFO:Checking exceptions
2025-07-01 12:43:17,300:INFO:Importing libraries
2025-07-01 12:43:17,300:INFO:Copying training dataset
2025-07-01 12:43:17,311:INFO:Defining folds
2025-07-01 12:43:17,311:INFO:Declaring metric variables
2025-07-01 12:43:17,311:INFO:Importing untrained model
2025-07-01 12:43:17,312:INFO:Logistic Regression Imported successfully
2025-07-01 12:43:17,313:INFO:Starting cross validation
2025-07-01 12:43:17,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 12:43:18,194:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,211:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,217:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,218:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,235:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,255:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,257:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,265:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,294:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:18,469:INFO:Calculating mean and std
2025-07-01 12:43:18,472:INFO:Creating metrics dataframe
2025-07-01 12:43:18,476:INFO:Finalizing model
2025-07-01 12:43:19,082:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 12:43:19,084:INFO:Uploading results into container
2025-07-01 12:43:19,086:INFO:Uploading model into container now
2025-07-01 12:43:19,131:INFO:_master_model_container: 1
2025-07-01 12:43:19,131:INFO:_display_container: 2
2025-07-01 12:43:19,133:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-01 12:43:19,133:INFO:create_model() successfully completed......................................
2025-07-01 12:43:19,341:INFO:Initializing save_model()
2025-07-01 12:43:19,341:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=models/lr, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-01 12:43:19,341:INFO:Adding model into prep_pipe
2025-07-01 12:43:19,359:INFO:models/lr.pkl saved in current working directory
2025-07-01 12:43:19,385:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                (...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-07-01 12:43:19,385:INFO:save_model() successfully completed......................................
2025-07-01 12:43:19,550:INFO:Initializing plot_model()
2025-07-01 12:43:19,551:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC7DD5A0>, system=True)
2025-07-01 12:43:19,551:INFO:Checking exceptions
2025-07-01 12:43:19,566:INFO:Preloading libraries
2025-07-01 12:43:19,567:INFO:Copying training dataset
2025-07-01 12:43:19,567:INFO:Plot type: confusion_matrix
2025-07-01 12:43:20,515:INFO:Fitting Model
2025-07-01 12:43:20,515:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-07-01 12:43:20,516:INFO:Scoring test/hold-out set
2025-07-01 12:43:23,867:INFO:Initializing plot_model()
2025-07-01 12:43:23,867:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC7DD5A0>, system=True)
2025-07-01 12:43:23,867:INFO:Checking exceptions
2025-07-01 12:43:23,873:INFO:Preloading libraries
2025-07-01 12:43:23,873:INFO:Copying training dataset
2025-07-01 12:43:23,874:INFO:Plot type: auc
2025-07-01 12:43:24,478:INFO:Fitting Model
2025-07-01 12:43:24,479:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-07-01 12:43:24,480:INFO:Scoring test/hold-out set
2025-07-01 12:43:30,564:INFO:Initializing plot_model()
2025-07-01 12:43:30,564:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000026EBC7DD5A0>, system=True)
2025-07-01 12:43:30,564:INFO:Checking exceptions
2025-07-01 12:43:30,566:INFO:Preloading libraries
2025-07-01 12:43:30,566:INFO:Copying training dataset
2025-07-01 12:43:30,566:INFO:Plot type: feature
2025-07-01 12:43:32,956:INFO:Visual Rendered Successfully
2025-07-01 12:43:33,051:INFO:plot_model() successfully completed......................................
2025-07-01 13:10:56,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 13:10:56,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 13:10:56,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 13:10:56,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-07-01 13:11:01,642:INFO:PyCaret ClassificationExperiment
2025-07-01 13:11:01,642:INFO:Logging name: clf-default-name
2025-07-01 13:11:01,642:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-01 13:11:01,642:INFO:version 3.3.2
2025-07-01 13:11:01,642:INFO:Initializing setup()
2025-07-01 13:11:01,642:INFO:self.USI: 905d
2025-07-01 13:11:01,642:INFO:self._variable_keys: {'pipeline', 'gpu_param', 'USI', 'X_test', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'n_jobs_param', 'fold_generator', 'exp_name_log', 'data', 'X_train', 'memory', 'fold_shuffle_param', 'y', 'y_test', 'fix_imbalance', '_available_plots', 'is_multiclass', 'idx', 'fold_groups_param', 'y_train', 'html_param', 'target_param', 'X', 'logging_param', '_ml_usecase', 'exp_id'}
2025-07-01 13:11:01,642:INFO:Checking environment
2025-07-01 13:11:01,643:INFO:python_version: 3.10.4
2025-07-01 13:11:01,643:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-07-01 13:11:01,643:INFO:machine: AMD64
2025-07-01 13:11:01,707:INFO:platform: Windows-10-10.0.26100-SP0
2025-07-01 13:11:01,722:INFO:Memory: svmem(total=16871448576, available=2138402816, percent=87.3, used=14733045760, free=2138402816)
2025-07-01 13:11:01,722:INFO:Physical Core: 10
2025-07-01 13:11:01,722:INFO:Logical Core: 12
2025-07-01 13:11:01,722:INFO:Checking libraries
2025-07-01 13:11:01,722:INFO:System:
2025-07-01 13:11:01,722:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-07-01 13:11:01,722:INFO:executable: C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\Scripts\python.exe
2025-07-01 13:11:01,722:INFO:   machine: Windows-10-10.0.26100-SP0
2025-07-01 13:11:01,722:INFO:PyCaret required dependencies:
2025-07-01 13:11:01,743:INFO:                 pip: 22.0.4
2025-07-01 13:11:01,743:INFO:          setuptools: 58.1.0
2025-07-01 13:11:01,743:INFO:             pycaret: 3.3.2
2025-07-01 13:11:01,743:INFO:             IPython: 8.37.0
2025-07-01 13:11:01,743:INFO:          ipywidgets: 8.1.7
2025-07-01 13:11:01,743:INFO:                tqdm: 4.67.1
2025-07-01 13:11:01,743:INFO:               numpy: 1.26.4
2025-07-01 13:11:01,743:INFO:              pandas: 2.1.4
2025-07-01 13:11:01,743:INFO:              jinja2: 3.1.6
2025-07-01 13:11:01,743:INFO:               scipy: 1.11.4
2025-07-01 13:11:01,743:INFO:              joblib: 1.3.2
2025-07-01 13:11:01,743:INFO:             sklearn: 1.4.2
2025-07-01 13:11:01,743:INFO:                pyod: 2.0.5
2025-07-01 13:11:01,743:INFO:            imblearn: 0.13.0
2025-07-01 13:11:01,743:INFO:   category_encoders: 2.7.0
2025-07-01 13:11:01,743:INFO:            lightgbm: 4.6.0
2025-07-01 13:11:01,743:INFO:               numba: 0.61.2
2025-07-01 13:11:01,743:INFO:            requests: 2.32.4
2025-07-01 13:11:01,743:INFO:          matplotlib: 3.7.5
2025-07-01 13:11:01,743:INFO:          scikitplot: 0.3.7
2025-07-01 13:11:01,743:INFO:         yellowbrick: 1.5
2025-07-01 13:11:01,743:INFO:              plotly: 5.24.1
2025-07-01 13:11:01,743:INFO:    plotly-resampler: Not installed
2025-07-01 13:11:01,743:INFO:             kaleido: 1.0.0
2025-07-01 13:11:01,743:INFO:           schemdraw: 0.15
2025-07-01 13:11:01,743:INFO:         statsmodels: 0.14.4
2025-07-01 13:11:01,743:INFO:              sktime: 0.26.0
2025-07-01 13:11:01,743:INFO:               tbats: 1.1.3
2025-07-01 13:11:01,743:INFO:            pmdarima: 2.0.4
2025-07-01 13:11:01,743:INFO:              psutil: 7.0.0
2025-07-01 13:11:01,743:INFO:          markupsafe: 3.0.2
2025-07-01 13:11:01,744:INFO:             pickle5: Not installed
2025-07-01 13:11:01,744:INFO:         cloudpickle: 3.1.1
2025-07-01 13:11:01,744:INFO:         deprecation: 2.1.0
2025-07-01 13:11:01,744:INFO:              xxhash: 3.5.0
2025-07-01 13:11:01,744:INFO:           wurlitzer: Not installed
2025-07-01 13:11:01,744:INFO:PyCaret optional dependencies:
2025-07-01 13:11:01,756:INFO:                shap: Not installed
2025-07-01 13:11:01,756:INFO:           interpret: Not installed
2025-07-01 13:11:01,756:INFO:                umap: Not installed
2025-07-01 13:11:01,756:INFO:     ydata_profiling: Not installed
2025-07-01 13:11:01,756:INFO:  explainerdashboard: Not installed
2025-07-01 13:11:01,756:INFO:             autoviz: Not installed
2025-07-01 13:11:01,756:INFO:           fairlearn: Not installed
2025-07-01 13:11:01,756:INFO:          deepchecks: Not installed
2025-07-01 13:11:01,756:INFO:             xgboost: Not installed
2025-07-01 13:11:01,756:INFO:            catboost: Not installed
2025-07-01 13:11:01,756:INFO:              kmodes: Not installed
2025-07-01 13:11:01,756:INFO:             mlxtend: Not installed
2025-07-01 13:11:01,756:INFO:       statsforecast: Not installed
2025-07-01 13:11:01,756:INFO:        tune_sklearn: Not installed
2025-07-01 13:11:01,757:INFO:                 ray: Not installed
2025-07-01 13:11:01,757:INFO:            hyperopt: Not installed
2025-07-01 13:11:01,757:INFO:              optuna: Not installed
2025-07-01 13:11:01,757:INFO:               skopt: Not installed
2025-07-01 13:11:01,757:INFO:              mlflow: Not installed
2025-07-01 13:11:01,757:INFO:              gradio: Not installed
2025-07-01 13:11:01,757:INFO:             fastapi: 0.115.14
2025-07-01 13:11:01,757:INFO:             uvicorn: 0.34.3
2025-07-01 13:11:01,757:INFO:              m2cgen: Not installed
2025-07-01 13:11:01,757:INFO:           evidently: Not installed
2025-07-01 13:11:01,757:INFO:               fugue: Not installed
2025-07-01 13:11:01,757:INFO:           streamlit: Not installed
2025-07-01 13:11:01,757:INFO:             prophet: Not installed
2025-07-01 13:11:01,757:INFO:None
2025-07-01 13:11:01,757:INFO:Set up data.
2025-07-01 13:11:01,760:INFO:Set up folding strategy.
2025-07-01 13:11:01,760:INFO:Set up train/test split.
2025-07-01 13:11:01,765:INFO:Set up index.
2025-07-01 13:11:01,765:INFO:Assigning column types.
2025-07-01 13:11:01,767:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-01 13:11:01,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 13:11:01,797:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:01,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 13:11:01,850:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:01,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,866:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-01 13:11:01,905:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:01,921:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:01,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:01,973:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-01 13:11:02,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,083:INFO:Preparing preprocessing pipeline...
2025-07-01 13:11:02,084:INFO:Set up simple imputation.
2025-07-01 13:11:02,086:INFO:Set up encoding of categorical features.
2025-07-01 13:11:02,126:INFO:Finished creating preprocessing pipeline.
2025-07-01 13:11:02,132:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-01 13:11:02,132:INFO:Creating final display dataframe.
2025-07-01 13:11:02,223:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape         (768, 10)
4        Transformed data shape         (768, 14)
5   Transformed train set shape         (537, 14)
6    Transformed test set shape         (231, 14)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              905d
2025-07-01 13:11:02,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,349:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:02,351:INFO:setup() successfully completed in 0.72s...............
2025-07-01 13:11:02,351:INFO:Initializing compare_models()
2025-07-01 13:11:02,351:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=10, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 10, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-07-01 13:11:02,351:INFO:Checking exceptions
2025-07-01 13:11:02,355:INFO:Preparing display monitor
2025-07-01 13:11:02,359:INFO:Initializing Logistic Regression
2025-07-01 13:11:02,359:INFO:Total runtime is 0.0 minutes
2025-07-01 13:11:02,359:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:02,360:INFO:Initializing create_model()
2025-07-01 13:11:02,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:02,360:INFO:Checking exceptions
2025-07-01 13:11:02,360:INFO:Importing libraries
2025-07-01 13:11:02,360:INFO:Copying training dataset
2025-07-01 13:11:02,365:INFO:Defining folds
2025-07-01 13:11:02,365:INFO:Declaring metric variables
2025-07-01 13:11:02,365:INFO:Importing untrained model
2025-07-01 13:11:02,366:INFO:Logistic Regression Imported successfully
2025-07-01 13:11:02,366:INFO:Starting cross validation
2025-07-01 13:11:02,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:12,026:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,117:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,406:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,457:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,493:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,669:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,772:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,806:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,812:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:12,948:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:13,043:INFO:Calculating mean and std
2025-07-01 13:11:13,045:INFO:Creating metrics dataframe
2025-07-01 13:11:13,051:INFO:Uploading results into container
2025-07-01 13:11:13,052:INFO:Uploading model into container now
2025-07-01 13:11:13,053:INFO:_master_model_container: 1
2025-07-01 13:11:13,053:INFO:_display_container: 2
2025-07-01 13:11:13,054:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-01 13:11:13,054:INFO:create_model() successfully completed......................................
2025-07-01 13:11:13,164:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:13,165:INFO:Creating metrics dataframe
2025-07-01 13:11:13,169:INFO:Initializing K Neighbors Classifier
2025-07-01 13:11:13,169:INFO:Total runtime is 0.18017727136611938 minutes
2025-07-01 13:11:13,169:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:13,169:INFO:Initializing create_model()
2025-07-01 13:11:13,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:13,170:INFO:Checking exceptions
2025-07-01 13:11:13,170:INFO:Importing libraries
2025-07-01 13:11:13,170:INFO:Copying training dataset
2025-07-01 13:11:13,174:INFO:Defining folds
2025-07-01 13:11:13,175:INFO:Declaring metric variables
2025-07-01 13:11:13,175:INFO:Importing untrained model
2025-07-01 13:11:13,176:INFO:K Neighbors Classifier Imported successfully
2025-07-01 13:11:13,176:INFO:Starting cross validation
2025-07-01 13:11:13,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:16,831:INFO:Calculating mean and std
2025-07-01 13:11:16,832:INFO:Creating metrics dataframe
2025-07-01 13:11:16,837:INFO:Uploading results into container
2025-07-01 13:11:16,838:INFO:Uploading model into container now
2025-07-01 13:11:16,838:INFO:_master_model_container: 2
2025-07-01 13:11:16,839:INFO:_display_container: 2
2025-07-01 13:11:16,839:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-01 13:11:16,839:INFO:create_model() successfully completed......................................
2025-07-01 13:11:16,925:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:16,925:INFO:Creating metrics dataframe
2025-07-01 13:11:16,928:INFO:Initializing Naive Bayes
2025-07-01 13:11:16,928:INFO:Total runtime is 0.24282102584838866 minutes
2025-07-01 13:11:16,928:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:16,928:INFO:Initializing create_model()
2025-07-01 13:11:16,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:16,929:INFO:Checking exceptions
2025-07-01 13:11:16,929:INFO:Importing libraries
2025-07-01 13:11:16,929:INFO:Copying training dataset
2025-07-01 13:11:16,933:INFO:Defining folds
2025-07-01 13:11:16,933:INFO:Declaring metric variables
2025-07-01 13:11:16,933:INFO:Importing untrained model
2025-07-01 13:11:16,934:INFO:Naive Bayes Imported successfully
2025-07-01 13:11:16,934:INFO:Starting cross validation
2025-07-01 13:11:16,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:17,208:INFO:Calculating mean and std
2025-07-01 13:11:17,211:INFO:Creating metrics dataframe
2025-07-01 13:11:17,217:INFO:Uploading results into container
2025-07-01 13:11:17,218:INFO:Uploading model into container now
2025-07-01 13:11:17,219:INFO:_master_model_container: 3
2025-07-01 13:11:17,220:INFO:_display_container: 2
2025-07-01 13:11:17,220:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-01 13:11:17,220:INFO:create_model() successfully completed......................................
2025-07-01 13:11:17,326:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:17,326:INFO:Creating metrics dataframe
2025-07-01 13:11:17,330:INFO:Initializing Decision Tree Classifier
2025-07-01 13:11:17,330:INFO:Total runtime is 0.24951267639795938 minutes
2025-07-01 13:11:17,330:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:17,331:INFO:Initializing create_model()
2025-07-01 13:11:17,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:17,331:INFO:Checking exceptions
2025-07-01 13:11:17,331:INFO:Importing libraries
2025-07-01 13:11:17,331:INFO:Copying training dataset
2025-07-01 13:11:17,336:INFO:Defining folds
2025-07-01 13:11:17,337:INFO:Declaring metric variables
2025-07-01 13:11:17,337:INFO:Importing untrained model
2025-07-01 13:11:17,338:INFO:Decision Tree Classifier Imported successfully
2025-07-01 13:11:17,339:INFO:Starting cross validation
2025-07-01 13:11:17,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:17,598:INFO:Calculating mean and std
2025-07-01 13:11:17,600:INFO:Creating metrics dataframe
2025-07-01 13:11:17,605:INFO:Uploading results into container
2025-07-01 13:11:17,606:INFO:Uploading model into container now
2025-07-01 13:11:17,607:INFO:_master_model_container: 4
2025-07-01 13:11:17,607:INFO:_display_container: 2
2025-07-01 13:11:17,608:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-07-01 13:11:17,608:INFO:create_model() successfully completed......................................
2025-07-01 13:11:17,689:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:17,689:INFO:Creating metrics dataframe
2025-07-01 13:11:17,693:INFO:Initializing SVM - Linear Kernel
2025-07-01 13:11:17,693:INFO:Total runtime is 0.2555671215057373 minutes
2025-07-01 13:11:17,693:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:17,694:INFO:Initializing create_model()
2025-07-01 13:11:17,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:17,694:INFO:Checking exceptions
2025-07-01 13:11:17,694:INFO:Importing libraries
2025-07-01 13:11:17,694:INFO:Copying training dataset
2025-07-01 13:11:17,698:INFO:Defining folds
2025-07-01 13:11:17,699:INFO:Declaring metric variables
2025-07-01 13:11:17,699:INFO:Importing untrained model
2025-07-01 13:11:17,699:INFO:SVM - Linear Kernel Imported successfully
2025-07-01 13:11:17,700:INFO:Starting cross validation
2025-07-01 13:11:17,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:17,908:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:17,925:INFO:Calculating mean and std
2025-07-01 13:11:17,927:INFO:Creating metrics dataframe
2025-07-01 13:11:17,931:INFO:Uploading results into container
2025-07-01 13:11:17,932:INFO:Uploading model into container now
2025-07-01 13:11:17,932:INFO:_master_model_container: 5
2025-07-01 13:11:17,932:INFO:_display_container: 2
2025-07-01 13:11:17,933:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-07-01 13:11:17,933:INFO:create_model() successfully completed......................................
2025-07-01 13:11:18,018:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:18,018:INFO:Creating metrics dataframe
2025-07-01 13:11:18,023:INFO:Initializing Ridge Classifier
2025-07-01 13:11:18,023:INFO:Total runtime is 0.26106984217961626 minutes
2025-07-01 13:11:18,024:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:18,024:INFO:Initializing create_model()
2025-07-01 13:11:18,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:18,024:INFO:Checking exceptions
2025-07-01 13:11:18,024:INFO:Importing libraries
2025-07-01 13:11:18,024:INFO:Copying training dataset
2025-07-01 13:11:18,029:INFO:Defining folds
2025-07-01 13:11:18,030:INFO:Declaring metric variables
2025-07-01 13:11:18,030:INFO:Importing untrained model
2025-07-01 13:11:18,031:INFO:Ridge Classifier Imported successfully
2025-07-01 13:11:18,031:INFO:Starting cross validation
2025-07-01 13:11:18,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:18,236:INFO:Calculating mean and std
2025-07-01 13:11:18,238:INFO:Creating metrics dataframe
2025-07-01 13:11:18,241:INFO:Uploading results into container
2025-07-01 13:11:18,242:INFO:Uploading model into container now
2025-07-01 13:11:18,243:INFO:_master_model_container: 6
2025-07-01 13:11:18,243:INFO:_display_container: 2
2025-07-01 13:11:18,244:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-01 13:11:18,244:INFO:create_model() successfully completed......................................
2025-07-01 13:11:18,324:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:18,324:INFO:Creating metrics dataframe
2025-07-01 13:11:18,329:INFO:Initializing Random Forest Classifier
2025-07-01 13:11:18,329:INFO:Total runtime is 0.2661634484926859 minutes
2025-07-01 13:11:18,329:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:18,330:INFO:Initializing create_model()
2025-07-01 13:11:18,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:18,330:INFO:Checking exceptions
2025-07-01 13:11:18,330:INFO:Importing libraries
2025-07-01 13:11:18,330:INFO:Copying training dataset
2025-07-01 13:11:18,336:INFO:Defining folds
2025-07-01 13:11:18,336:INFO:Declaring metric variables
2025-07-01 13:11:18,337:INFO:Importing untrained model
2025-07-01 13:11:18,337:INFO:Random Forest Classifier Imported successfully
2025-07-01 13:11:18,339:INFO:Starting cross validation
2025-07-01 13:11:18,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:19,470:INFO:Calculating mean and std
2025-07-01 13:11:19,472:INFO:Creating metrics dataframe
2025-07-01 13:11:19,475:INFO:Uploading results into container
2025-07-01 13:11:19,476:INFO:Uploading model into container now
2025-07-01 13:11:19,477:INFO:_master_model_container: 7
2025-07-01 13:11:19,477:INFO:_display_container: 2
2025-07-01 13:11:19,478:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-01 13:11:19,478:INFO:create_model() successfully completed......................................
2025-07-01 13:11:19,581:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:19,582:INFO:Creating metrics dataframe
2025-07-01 13:11:19,588:INFO:Initializing Quadratic Discriminant Analysis
2025-07-01 13:11:19,588:INFO:Total runtime is 0.2871462702751159 minutes
2025-07-01 13:11:19,589:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:19,589:INFO:Initializing create_model()
2025-07-01 13:11:19,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:19,590:INFO:Checking exceptions
2025-07-01 13:11:19,590:INFO:Importing libraries
2025-07-01 13:11:19,590:INFO:Copying training dataset
2025-07-01 13:11:19,600:INFO:Defining folds
2025-07-01 13:11:19,601:INFO:Declaring metric variables
2025-07-01 13:11:19,601:INFO:Importing untrained model
2025-07-01 13:11:19,602:INFO:Quadratic Discriminant Analysis Imported successfully
2025-07-01 13:11:19,603:INFO:Starting cross validation
2025-07-01 13:11:19,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:19,750:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,750:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,750:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,757:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,757:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,768:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,775:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,785:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,787:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-07-01 13:11:19,891:INFO:Calculating mean and std
2025-07-01 13:11:19,892:INFO:Creating metrics dataframe
2025-07-01 13:11:19,898:INFO:Uploading results into container
2025-07-01 13:11:19,900:INFO:Uploading model into container now
2025-07-01 13:11:19,901:INFO:_master_model_container: 8
2025-07-01 13:11:19,902:INFO:_display_container: 2
2025-07-01 13:11:19,902:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-07-01 13:11:19,903:INFO:create_model() successfully completed......................................
2025-07-01 13:11:20,007:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:20,007:INFO:Creating metrics dataframe
2025-07-01 13:11:20,010:INFO:Initializing Ada Boost Classifier
2025-07-01 13:11:20,010:INFO:Total runtime is 0.29418814579645786 minutes
2025-07-01 13:11:20,011:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:20,011:INFO:Initializing create_model()
2025-07-01 13:11:20,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:20,011:INFO:Checking exceptions
2025-07-01 13:11:20,011:INFO:Importing libraries
2025-07-01 13:11:20,011:INFO:Copying training dataset
2025-07-01 13:11:20,016:INFO:Defining folds
2025-07-01 13:11:20,016:INFO:Declaring metric variables
2025-07-01 13:11:20,016:INFO:Importing untrained model
2025-07-01 13:11:20,016:INFO:Ada Boost Classifier Imported successfully
2025-07-01 13:11:20,017:INFO:Starting cross validation
2025-07-01 13:11:20,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:20,119:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,119:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,120:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,127:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,131:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,131:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,134:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,141:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,148:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,150:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:20,623:INFO:Calculating mean and std
2025-07-01 13:11:20,623:INFO:Creating metrics dataframe
2025-07-01 13:11:20,627:INFO:Uploading results into container
2025-07-01 13:11:20,628:INFO:Uploading model into container now
2025-07-01 13:11:20,630:INFO:_master_model_container: 9
2025-07-01 13:11:20,630:INFO:_display_container: 2
2025-07-01 13:11:20,630:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-01 13:11:20,630:INFO:create_model() successfully completed......................................
2025-07-01 13:11:20,722:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:20,722:INFO:Creating metrics dataframe
2025-07-01 13:11:20,725:INFO:Initializing Gradient Boosting Classifier
2025-07-01 13:11:20,725:INFO:Total runtime is 0.30610889593760165 minutes
2025-07-01 13:11:20,725:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:20,726:INFO:Initializing create_model()
2025-07-01 13:11:20,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:20,726:INFO:Checking exceptions
2025-07-01 13:11:20,726:INFO:Importing libraries
2025-07-01 13:11:20,726:INFO:Copying training dataset
2025-07-01 13:11:20,729:INFO:Defining folds
2025-07-01 13:11:20,730:INFO:Declaring metric variables
2025-07-01 13:11:20,730:INFO:Importing untrained model
2025-07-01 13:11:20,730:INFO:Gradient Boosting Classifier Imported successfully
2025-07-01 13:11:20,731:INFO:Starting cross validation
2025-07-01 13:11:20,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:21,500:INFO:Calculating mean and std
2025-07-01 13:11:21,501:INFO:Creating metrics dataframe
2025-07-01 13:11:21,504:INFO:Uploading results into container
2025-07-01 13:11:21,506:INFO:Uploading model into container now
2025-07-01 13:11:21,506:INFO:_master_model_container: 10
2025-07-01 13:11:21,507:INFO:_display_container: 2
2025-07-01 13:11:21,507:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-01 13:11:21,507:INFO:create_model() successfully completed......................................
2025-07-01 13:11:21,604:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:21,604:INFO:Creating metrics dataframe
2025-07-01 13:11:21,608:INFO:Initializing Linear Discriminant Analysis
2025-07-01 13:11:21,608:INFO:Total runtime is 0.3208115975062052 minutes
2025-07-01 13:11:21,608:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:21,609:INFO:Initializing create_model()
2025-07-01 13:11:21,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:21,609:INFO:Checking exceptions
2025-07-01 13:11:21,609:INFO:Importing libraries
2025-07-01 13:11:21,609:INFO:Copying training dataset
2025-07-01 13:11:21,616:INFO:Defining folds
2025-07-01 13:11:21,616:INFO:Declaring metric variables
2025-07-01 13:11:21,617:INFO:Importing untrained model
2025-07-01 13:11:21,617:INFO:Linear Discriminant Analysis Imported successfully
2025-07-01 13:11:21,618:INFO:Starting cross validation
2025-07-01 13:11:21,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:21,938:INFO:Calculating mean and std
2025-07-01 13:11:21,940:INFO:Creating metrics dataframe
2025-07-01 13:11:21,945:INFO:Uploading results into container
2025-07-01 13:11:21,947:INFO:Uploading model into container now
2025-07-01 13:11:21,948:INFO:_master_model_container: 11
2025-07-01 13:11:21,948:INFO:_display_container: 2
2025-07-01 13:11:21,949:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-01 13:11:21,949:INFO:create_model() successfully completed......................................
2025-07-01 13:11:22,058:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:22,059:INFO:Creating metrics dataframe
2025-07-01 13:11:22,063:INFO:Initializing Extra Trees Classifier
2025-07-01 13:11:22,063:INFO:Total runtime is 0.3284043351809183 minutes
2025-07-01 13:11:22,063:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:22,064:INFO:Initializing create_model()
2025-07-01 13:11:22,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:22,064:INFO:Checking exceptions
2025-07-01 13:11:22,064:INFO:Importing libraries
2025-07-01 13:11:22,064:INFO:Copying training dataset
2025-07-01 13:11:22,069:INFO:Defining folds
2025-07-01 13:11:22,069:INFO:Declaring metric variables
2025-07-01 13:11:22,069:INFO:Importing untrained model
2025-07-01 13:11:22,070:INFO:Extra Trees Classifier Imported successfully
2025-07-01 13:11:22,070:INFO:Starting cross validation
2025-07-01 13:11:22,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:23,150:INFO:Calculating mean and std
2025-07-01 13:11:23,153:INFO:Creating metrics dataframe
2025-07-01 13:11:23,156:INFO:Uploading results into container
2025-07-01 13:11:23,156:INFO:Uploading model into container now
2025-07-01 13:11:23,157:INFO:_master_model_container: 12
2025-07-01 13:11:23,157:INFO:_display_container: 2
2025-07-01 13:11:23,158:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-01 13:11:23,158:INFO:create_model() successfully completed......................................
2025-07-01 13:11:23,249:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:23,249:INFO:Creating metrics dataframe
2025-07-01 13:11:23,252:INFO:Initializing Light Gradient Boosting Machine
2025-07-01 13:11:23,252:INFO:Total runtime is 0.3482208490371704 minutes
2025-07-01 13:11:23,253:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:23,253:INFO:Initializing create_model()
2025-07-01 13:11:23,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:23,253:INFO:Checking exceptions
2025-07-01 13:11:23,253:INFO:Importing libraries
2025-07-01 13:11:23,253:INFO:Copying training dataset
2025-07-01 13:11:23,258:INFO:Defining folds
2025-07-01 13:11:23,259:INFO:Declaring metric variables
2025-07-01 13:11:23,259:INFO:Importing untrained model
2025-07-01 13:11:23,261:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-01 13:11:23,261:INFO:Starting cross validation
2025-07-01 13:11:23,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:26,055:INFO:Calculating mean and std
2025-07-01 13:11:26,057:INFO:Creating metrics dataframe
2025-07-01 13:11:26,060:INFO:Uploading results into container
2025-07-01 13:11:26,061:INFO:Uploading model into container now
2025-07-01 13:11:26,061:INFO:_master_model_container: 13
2025-07-01 13:11:26,061:INFO:_display_container: 2
2025-07-01 13:11:26,063:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-01 13:11:26,063:INFO:create_model() successfully completed......................................
2025-07-01 13:11:26,172:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:26,173:INFO:Creating metrics dataframe
2025-07-01 13:11:26,182:INFO:Initializing Dummy Classifier
2025-07-01 13:11:26,183:INFO:Total runtime is 0.3970617810885111 minutes
2025-07-01 13:11:26,183:INFO:SubProcess create_model() called ==================================
2025-07-01 13:11:26,184:INFO:Initializing create_model()
2025-07-01 13:11:26,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012E846FBE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:26,184:INFO:Checking exceptions
2025-07-01 13:11:26,184:INFO:Importing libraries
2025-07-01 13:11:26,185:INFO:Copying training dataset
2025-07-01 13:11:26,197:INFO:Defining folds
2025-07-01 13:11:26,197:INFO:Declaring metric variables
2025-07-01 13:11:26,198:INFO:Importing untrained model
2025-07-01 13:11:26,199:INFO:Dummy Classifier Imported successfully
2025-07-01 13:11:26,199:INFO:Starting cross validation
2025-07-01 13:11:26,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:26,375:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,380:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,401:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,403:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,414:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,417:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,420:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,424:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-07-01 13:11:26,446:INFO:Calculating mean and std
2025-07-01 13:11:26,448:INFO:Creating metrics dataframe
2025-07-01 13:11:26,450:INFO:Uploading results into container
2025-07-01 13:11:26,451:INFO:Uploading model into container now
2025-07-01 13:11:26,451:INFO:_master_model_container: 14
2025-07-01 13:11:26,451:INFO:_display_container: 2
2025-07-01 13:11:26,453:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-07-01 13:11:26,453:INFO:create_model() successfully completed......................................
2025-07-01 13:11:26,534:INFO:SubProcess create_model() end ==================================
2025-07-01 13:11:26,535:INFO:Creating metrics dataframe
2025-07-01 13:11:26,548:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-07-01 13:11:26,551:INFO:Initializing create_model()
2025-07-01 13:11:26,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:26,551:INFO:Checking exceptions
2025-07-01 13:11:26,553:INFO:Importing libraries
2025-07-01 13:11:26,553:INFO:Copying training dataset
2025-07-01 13:11:26,557:INFO:Defining folds
2025-07-01 13:11:26,557:INFO:Declaring metric variables
2025-07-01 13:11:26,557:INFO:Importing untrained model
2025-07-01 13:11:26,557:INFO:Declaring custom model
2025-07-01 13:11:26,558:INFO:Ridge Classifier Imported successfully
2025-07-01 13:11:26,560:INFO:Cross validation set to False
2025-07-01 13:11:26,560:INFO:Fitting Model
2025-07-01 13:11:26,602:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-01 13:11:26,602:INFO:create_model() successfully completed......................................
2025-07-01 13:11:26,674:INFO:Initializing create_model()
2025-07-01 13:11:26,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:26,675:INFO:Checking exceptions
2025-07-01 13:11:26,675:INFO:Importing libraries
2025-07-01 13:11:26,676:INFO:Copying training dataset
2025-07-01 13:11:26,679:INFO:Defining folds
2025-07-01 13:11:26,679:INFO:Declaring metric variables
2025-07-01 13:11:26,679:INFO:Importing untrained model
2025-07-01 13:11:26,679:INFO:Declaring custom model
2025-07-01 13:11:26,680:INFO:Linear Discriminant Analysis Imported successfully
2025-07-01 13:11:26,681:INFO:Cross validation set to False
2025-07-01 13:11:26,681:INFO:Fitting Model
2025-07-01 13:11:26,722:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-07-01 13:11:26,723:INFO:create_model() successfully completed......................................
2025-07-01 13:11:26,803:INFO:Initializing create_model()
2025-07-01 13:11:26,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:26,804:INFO:Checking exceptions
2025-07-01 13:11:26,806:INFO:Importing libraries
2025-07-01 13:11:26,806:INFO:Copying training dataset
2025-07-01 13:11:26,815:INFO:Defining folds
2025-07-01 13:11:26,815:INFO:Declaring metric variables
2025-07-01 13:11:26,815:INFO:Importing untrained model
2025-07-01 13:11:26,815:INFO:Declaring custom model
2025-07-01 13:11:26,816:INFO:Logistic Regression Imported successfully
2025-07-01 13:11:26,819:INFO:Cross validation set to False
2025-07-01 13:11:26,820:INFO:Fitting Model
2025-07-01 13:11:26,949:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:11:26,950:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-01 13:11:26,951:INFO:create_model() successfully completed......................................
2025-07-01 13:11:27,014:INFO:Initializing create_model()
2025-07-01 13:11:27,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:27,014:INFO:Checking exceptions
2025-07-01 13:11:27,015:INFO:Importing libraries
2025-07-01 13:11:27,015:INFO:Copying training dataset
2025-07-01 13:11:27,018:INFO:Defining folds
2025-07-01 13:11:27,018:INFO:Declaring metric variables
2025-07-01 13:11:27,018:INFO:Importing untrained model
2025-07-01 13:11:27,018:INFO:Declaring custom model
2025-07-01 13:11:27,018:INFO:Random Forest Classifier Imported successfully
2025-07-01 13:11:27,019:INFO:Cross validation set to False
2025-07-01 13:11:27,019:INFO:Fitting Model
2025-07-01 13:11:27,217:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-07-01 13:11:27,218:INFO:create_model() successfully completed......................................
2025-07-01 13:11:27,280:INFO:Initializing create_model()
2025-07-01 13:11:27,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:27,280:INFO:Checking exceptions
2025-07-01 13:11:27,281:INFO:Importing libraries
2025-07-01 13:11:27,281:INFO:Copying training dataset
2025-07-01 13:11:27,284:INFO:Defining folds
2025-07-01 13:11:27,284:INFO:Declaring metric variables
2025-07-01 13:11:27,284:INFO:Importing untrained model
2025-07-01 13:11:27,284:INFO:Declaring custom model
2025-07-01 13:11:27,284:INFO:Ada Boost Classifier Imported successfully
2025-07-01 13:11:27,285:INFO:Cross validation set to False
2025-07-01 13:11:27,285:INFO:Fitting Model
2025-07-01 13:11:27,313:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-07-01 13:11:27,392:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-07-01 13:11:27,392:INFO:create_model() successfully completed......................................
2025-07-01 13:11:27,470:INFO:Initializing create_model()
2025-07-01 13:11:27,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:27,471:INFO:Checking exceptions
2025-07-01 13:11:27,472:INFO:Importing libraries
2025-07-01 13:11:27,472:INFO:Copying training dataset
2025-07-01 13:11:27,476:INFO:Defining folds
2025-07-01 13:11:27,476:INFO:Declaring metric variables
2025-07-01 13:11:27,476:INFO:Importing untrained model
2025-07-01 13:11:27,476:INFO:Declaring custom model
2025-07-01 13:11:27,477:INFO:Gradient Boosting Classifier Imported successfully
2025-07-01 13:11:27,478:INFO:Cross validation set to False
2025-07-01 13:11:27,478:INFO:Fitting Model
2025-07-01 13:11:27,771:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-07-01 13:11:27,771:INFO:create_model() successfully completed......................................
2025-07-01 13:11:27,858:INFO:Initializing create_model()
2025-07-01 13:11:27,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:27,858:INFO:Checking exceptions
2025-07-01 13:11:27,859:INFO:Importing libraries
2025-07-01 13:11:27,860:INFO:Copying training dataset
2025-07-01 13:11:27,864:INFO:Defining folds
2025-07-01 13:11:27,864:INFO:Declaring metric variables
2025-07-01 13:11:27,864:INFO:Importing untrained model
2025-07-01 13:11:27,864:INFO:Declaring custom model
2025-07-01 13:11:27,865:INFO:Extra Trees Classifier Imported successfully
2025-07-01 13:11:27,866:INFO:Cross validation set to False
2025-07-01 13:11:27,866:INFO:Fitting Model
2025-07-01 13:11:28,028:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-07-01 13:11:28,029:INFO:create_model() successfully completed......................................
2025-07-01 13:11:28,102:INFO:Initializing create_model()
2025-07-01 13:11:28,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:28,103:INFO:Checking exceptions
2025-07-01 13:11:28,104:INFO:Importing libraries
2025-07-01 13:11:28,105:INFO:Copying training dataset
2025-07-01 13:11:28,109:INFO:Defining folds
2025-07-01 13:11:28,109:INFO:Declaring metric variables
2025-07-01 13:11:28,109:INFO:Importing untrained model
2025-07-01 13:11:28,110:INFO:Declaring custom model
2025-07-01 13:11:28,110:INFO:K Neighbors Classifier Imported successfully
2025-07-01 13:11:28,111:INFO:Cross validation set to False
2025-07-01 13:11:28,112:INFO:Fitting Model
2025-07-01 13:11:28,149:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-07-01 13:11:28,149:INFO:create_model() successfully completed......................................
2025-07-01 13:11:28,218:INFO:Initializing create_model()
2025-07-01 13:11:28,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:28,218:INFO:Checking exceptions
2025-07-01 13:11:28,219:INFO:Importing libraries
2025-07-01 13:11:28,219:INFO:Copying training dataset
2025-07-01 13:11:28,222:INFO:Defining folds
2025-07-01 13:11:28,222:INFO:Declaring metric variables
2025-07-01 13:11:28,222:INFO:Importing untrained model
2025-07-01 13:11:28,222:INFO:Declaring custom model
2025-07-01 13:11:28,223:INFO:Light Gradient Boosting Machine Imported successfully
2025-07-01 13:11:28,225:INFO:Cross validation set to False
2025-07-01 13:11:28,225:INFO:Fitting Model
2025-07-01 13:11:28,266:INFO:[LightGBM] [Info] Number of positive: 187, number of negative: 350
2025-07-01 13:11:28,267:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2025-07-01 13:11:28,267:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-07-01 13:11:28,267:INFO:[LightGBM] [Info] Total Bins 622
2025-07-01 13:11:28,267:INFO:[LightGBM] [Info] Number of data points in the train set: 537, number of used features: 13
2025-07-01 13:11:28,268:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348231 -> initscore=-0.626825
2025-07-01 13:11:28,268:INFO:[LightGBM] [Info] Start training from score -0.626825
2025-07-01 13:11:28,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-07-01 13:11:28,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-07-01 13:11:28,434:INFO:create_model() successfully completed......................................
2025-07-01 13:11:28,522:INFO:Initializing create_model()
2025-07-01 13:11:28,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E843B4340>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:28,522:INFO:Checking exceptions
2025-07-01 13:11:28,523:INFO:Importing libraries
2025-07-01 13:11:28,523:INFO:Copying training dataset
2025-07-01 13:11:28,533:INFO:Defining folds
2025-07-01 13:11:28,533:INFO:Declaring metric variables
2025-07-01 13:11:28,534:INFO:Importing untrained model
2025-07-01 13:11:28,534:INFO:Declaring custom model
2025-07-01 13:11:28,535:INFO:Naive Bayes Imported successfully
2025-07-01 13:11:28,537:INFO:Cross validation set to False
2025-07-01 13:11:28,538:INFO:Fitting Model
2025-07-01 13:11:28,577:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-07-01 13:11:28,577:INFO:create_model() successfully completed......................................
2025-07-01 13:11:28,668:INFO:_master_model_container: 14
2025-07-01 13:11:28,669:INFO:_display_container: 2
2025-07-01 13:11:28,671:INFO:[RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GaussianNB(priors=None, var_smoothing=1e-09)]
2025-07-01 13:11:28,671:INFO:compare_models() successfully completed......................................
2025-07-01 13:11:29,221:INFO:PyCaret ClassificationExperiment
2025-07-01 13:11:29,222:INFO:Logging name: clf-default-name
2025-07-01 13:11:29,222:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-01 13:11:29,222:INFO:version 3.3.2
2025-07-01 13:11:29,222:INFO:Initializing setup()
2025-07-01 13:11:29,222:INFO:self.USI: 78de
2025-07-01 13:11:29,222:INFO:self._variable_keys: {'pipeline', 'gpu_param', 'USI', 'X_test', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'n_jobs_param', 'fold_generator', 'exp_name_log', 'data', 'X_train', 'memory', 'fold_shuffle_param', 'y', 'y_test', 'fix_imbalance', '_available_plots', 'is_multiclass', 'idx', 'fold_groups_param', 'y_train', 'html_param', 'target_param', 'X', 'logging_param', '_ml_usecase', 'exp_id'}
2025-07-01 13:11:29,222:INFO:Checking environment
2025-07-01 13:11:29,222:INFO:python_version: 3.10.4
2025-07-01 13:11:29,222:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-07-01 13:11:29,222:INFO:machine: AMD64
2025-07-01 13:11:29,222:INFO:platform: Windows-10-10.0.26100-SP0
2025-07-01 13:11:29,235:INFO:Memory: svmem(total=16871448576, available=865873920, percent=94.9, used=16005574656, free=865873920)
2025-07-01 13:11:29,235:INFO:Physical Core: 10
2025-07-01 13:11:29,235:INFO:Logical Core: 12
2025-07-01 13:11:29,235:INFO:Checking libraries
2025-07-01 13:11:29,235:INFO:System:
2025-07-01 13:11:29,235:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-07-01 13:11:29,235:INFO:executable: C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\Scripts\python.exe
2025-07-01 13:11:29,235:INFO:   machine: Windows-10-10.0.26100-SP0
2025-07-01 13:11:29,235:INFO:PyCaret required dependencies:
2025-07-01 13:11:29,235:INFO:                 pip: 22.0.4
2025-07-01 13:11:29,235:INFO:          setuptools: 58.1.0
2025-07-01 13:11:29,235:INFO:             pycaret: 3.3.2
2025-07-01 13:11:29,235:INFO:             IPython: 8.37.0
2025-07-01 13:11:29,235:INFO:          ipywidgets: 8.1.7
2025-07-01 13:11:29,235:INFO:                tqdm: 4.67.1
2025-07-01 13:11:29,235:INFO:               numpy: 1.26.4
2025-07-01 13:11:29,235:INFO:              pandas: 2.1.4
2025-07-01 13:11:29,235:INFO:              jinja2: 3.1.6
2025-07-01 13:11:29,235:INFO:               scipy: 1.11.4
2025-07-01 13:11:29,235:INFO:              joblib: 1.3.2
2025-07-01 13:11:29,235:INFO:             sklearn: 1.4.2
2025-07-01 13:11:29,235:INFO:                pyod: 2.0.5
2025-07-01 13:11:29,235:INFO:            imblearn: 0.13.0
2025-07-01 13:11:29,235:INFO:   category_encoders: 2.7.0
2025-07-01 13:11:29,235:INFO:            lightgbm: 4.6.0
2025-07-01 13:11:29,235:INFO:               numba: 0.61.2
2025-07-01 13:11:29,235:INFO:            requests: 2.32.4
2025-07-01 13:11:29,235:INFO:          matplotlib: 3.7.5
2025-07-01 13:11:29,235:INFO:          scikitplot: 0.3.7
2025-07-01 13:11:29,235:INFO:         yellowbrick: 1.5
2025-07-01 13:11:29,236:INFO:              plotly: 5.24.1
2025-07-01 13:11:29,236:INFO:    plotly-resampler: Not installed
2025-07-01 13:11:29,236:INFO:             kaleido: 1.0.0
2025-07-01 13:11:29,236:INFO:           schemdraw: 0.15
2025-07-01 13:11:29,236:INFO:         statsmodels: 0.14.4
2025-07-01 13:11:29,236:INFO:              sktime: 0.26.0
2025-07-01 13:11:29,236:INFO:               tbats: 1.1.3
2025-07-01 13:11:29,236:INFO:            pmdarima: 2.0.4
2025-07-01 13:11:29,236:INFO:              psutil: 7.0.0
2025-07-01 13:11:29,236:INFO:          markupsafe: 3.0.2
2025-07-01 13:11:29,236:INFO:             pickle5: Not installed
2025-07-01 13:11:29,236:INFO:         cloudpickle: 3.1.1
2025-07-01 13:11:29,236:INFO:         deprecation: 2.1.0
2025-07-01 13:11:29,236:INFO:              xxhash: 3.5.0
2025-07-01 13:11:29,236:INFO:           wurlitzer: Not installed
2025-07-01 13:11:29,236:INFO:PyCaret optional dependencies:
2025-07-01 13:11:29,236:INFO:                shap: Not installed
2025-07-01 13:11:29,236:INFO:           interpret: Not installed
2025-07-01 13:11:29,236:INFO:                umap: Not installed
2025-07-01 13:11:29,236:INFO:     ydata_profiling: Not installed
2025-07-01 13:11:29,236:INFO:  explainerdashboard: Not installed
2025-07-01 13:11:29,236:INFO:             autoviz: Not installed
2025-07-01 13:11:29,236:INFO:           fairlearn: Not installed
2025-07-01 13:11:29,236:INFO:          deepchecks: Not installed
2025-07-01 13:11:29,236:INFO:             xgboost: Not installed
2025-07-01 13:11:29,236:INFO:            catboost: Not installed
2025-07-01 13:11:29,236:INFO:              kmodes: Not installed
2025-07-01 13:11:29,236:INFO:             mlxtend: Not installed
2025-07-01 13:11:29,236:INFO:       statsforecast: Not installed
2025-07-01 13:11:29,236:INFO:        tune_sklearn: Not installed
2025-07-01 13:11:29,236:INFO:                 ray: Not installed
2025-07-01 13:11:29,236:INFO:            hyperopt: Not installed
2025-07-01 13:11:29,236:INFO:              optuna: Not installed
2025-07-01 13:11:29,236:INFO:               skopt: Not installed
2025-07-01 13:11:29,236:INFO:              mlflow: Not installed
2025-07-01 13:11:29,236:INFO:              gradio: Not installed
2025-07-01 13:11:29,236:INFO:             fastapi: 0.115.14
2025-07-01 13:11:29,236:INFO:             uvicorn: 0.34.3
2025-07-01 13:11:29,236:INFO:              m2cgen: Not installed
2025-07-01 13:11:29,236:INFO:           evidently: Not installed
2025-07-01 13:11:29,236:INFO:               fugue: Not installed
2025-07-01 13:11:29,236:INFO:           streamlit: Not installed
2025-07-01 13:11:29,236:INFO:             prophet: Not installed
2025-07-01 13:11:29,236:INFO:None
2025-07-01 13:11:29,236:INFO:Set up data.
2025-07-01 13:11:29,239:INFO:Set up folding strategy.
2025-07-01 13:11:29,240:INFO:Set up train/test split.
2025-07-01 13:11:29,242:INFO:Set up index.
2025-07-01 13:11:29,243:INFO:Assigning column types.
2025-07-01 13:11:29,245:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-01 13:11:29,272:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 13:11:29,273:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:29,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 13:11:29,347:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:29,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,369:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-01 13:11:29,431:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:29,453:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,490:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:11:29,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,522:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-01 13:11:29,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,674:INFO:Preparing preprocessing pipeline...
2025-07-01 13:11:29,675:INFO:Set up simple imputation.
2025-07-01 13:11:29,677:INFO:Set up encoding of categorical features.
2025-07-01 13:11:29,727:INFO:Finished creating preprocessing pipeline.
2025-07-01 13:11:29,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-01 13:11:29,732:INFO:Creating final display dataframe.
2025-07-01 13:11:29,849:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape         (768, 10)
4        Transformed data shape         (768, 14)
5   Transformed train set shape         (537, 14)
6    Transformed test set shape         (231, 14)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              78de
2025-07-01 13:11:29,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:29,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:30,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:30,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:11:30,038:INFO:setup() successfully completed in 0.82s...............
2025-07-01 13:11:30,038:INFO:Initializing create_model()
2025-07-01 13:11:30,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8490B9A0>, estimator=ridge, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:11:30,038:INFO:Checking exceptions
2025-07-01 13:11:30,040:INFO:Importing libraries
2025-07-01 13:11:30,040:INFO:Copying training dataset
2025-07-01 13:11:30,049:INFO:Defining folds
2025-07-01 13:11:30,049:INFO:Declaring metric variables
2025-07-01 13:11:30,050:INFO:Importing untrained model
2025-07-01 13:11:30,050:INFO:Ridge Classifier Imported successfully
2025-07-01 13:11:30,050:INFO:Starting cross validation
2025-07-01 13:11:30,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:11:30,293:INFO:Calculating mean and std
2025-07-01 13:11:30,295:INFO:Creating metrics dataframe
2025-07-01 13:11:30,300:INFO:Finalizing model
2025-07-01 13:11:30,359:INFO:Uploading results into container
2025-07-01 13:11:30,360:INFO:Uploading model into container now
2025-07-01 13:11:30,373:INFO:_master_model_container: 1
2025-07-01 13:11:30,373:INFO:_display_container: 2
2025-07-01 13:11:30,374:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-07-01 13:11:30,374:INFO:create_model() successfully completed......................................
2025-07-01 13:11:30,469:INFO:Initializing save_model()
2025-07-01 13:11:30,469:INFO:save_model(model=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), model_name=models/ridge, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-01 13:11:30,469:INFO:Adding model into prep_pipe
2025-07-01 13:11:30,475:INFO:models/ridge.pkl saved in current working directory
2025-07-01 13:11:30,481:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                (...
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True,
                                 fit_intercept=True, max_iter=None,
                                 positive=False, random_state=123,
                                 solver='auto', tol=0.0001))],
         verbose=False)
2025-07-01 13:11:30,481:INFO:save_model() successfully completed......................................
2025-07-01 13:11:30,552:INFO:Initializing plot_model()
2025-07-01 13:11:30,552:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8490B9A0>, system=True)
2025-07-01 13:11:30,552:INFO:Checking exceptions
2025-07-01 13:11:30,555:INFO:Preloading libraries
2025-07-01 13:11:30,555:INFO:Copying training dataset
2025-07-01 13:11:30,555:INFO:Plot type: confusion_matrix
2025-07-01 13:11:30,957:INFO:Fitting Model
2025-07-01 13:11:30,959:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2025-07-01 13:11:30,960:INFO:Scoring test/hold-out set
2025-07-01 13:11:42,418:INFO:Initializing plot_model()
2025-07-01 13:11:42,419:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8490B9A0>, system=True)
2025-07-01 13:11:42,419:INFO:Checking exceptions
2025-07-01 13:11:42,420:INFO:Initializing plot_model()
2025-07-01 13:11:42,420:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8490B9A0>, system=True)
2025-07-01 13:11:42,420:INFO:Checking exceptions
2025-07-01 13:11:42,426:INFO:Preloading libraries
2025-07-01 13:11:42,427:INFO:Copying training dataset
2025-07-01 13:11:42,427:INFO:Plot type: feature
2025-07-01 13:11:45,025:INFO:Visual Rendered Successfully
2025-07-01 13:11:45,164:INFO:plot_model() successfully completed......................................
2025-07-01 13:12:17,408:INFO:PyCaret ClassificationExperiment
2025-07-01 13:12:17,408:INFO:Logging name: clf-default-name
2025-07-01 13:12:17,408:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-07-01 13:12:17,408:INFO:version 3.3.2
2025-07-01 13:12:17,408:INFO:Initializing setup()
2025-07-01 13:12:17,408:INFO:self.USI: ef63
2025-07-01 13:12:17,408:INFO:self._variable_keys: {'pipeline', 'gpu_param', 'USI', 'X_test', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'n_jobs_param', 'fold_generator', 'exp_name_log', 'data', 'X_train', 'memory', 'fold_shuffle_param', 'y', 'y_test', 'fix_imbalance', '_available_plots', 'is_multiclass', 'idx', 'fold_groups_param', 'y_train', 'html_param', 'target_param', 'X', 'logging_param', '_ml_usecase', 'exp_id'}
2025-07-01 13:12:17,408:INFO:Checking environment
2025-07-01 13:12:17,408:INFO:python_version: 3.10.4
2025-07-01 13:12:17,408:INFO:python_build: ('tags/v3.10.4:9d38120', 'Mar 23 2022 23:13:41')
2025-07-01 13:12:17,408:INFO:machine: AMD64
2025-07-01 13:12:17,408:INFO:platform: Windows-10-10.0.26100-SP0
2025-07-01 13:12:17,422:INFO:Memory: svmem(total=16871448576, available=714235904, percent=95.8, used=16157212672, free=714235904)
2025-07-01 13:12:17,422:INFO:Physical Core: 10
2025-07-01 13:12:17,422:INFO:Logical Core: 12
2025-07-01 13:12:17,422:INFO:Checking libraries
2025-07-01 13:12:17,422:INFO:System:
2025-07-01 13:12:17,422:INFO:    python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
2025-07-01 13:12:17,422:INFO:executable: C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\Scripts\python.exe
2025-07-01 13:12:17,422:INFO:   machine: Windows-10-10.0.26100-SP0
2025-07-01 13:12:17,422:INFO:PyCaret required dependencies:
2025-07-01 13:12:17,422:INFO:                 pip: 22.0.4
2025-07-01 13:12:17,422:INFO:          setuptools: 58.1.0
2025-07-01 13:12:17,422:INFO:             pycaret: 3.3.2
2025-07-01 13:12:17,422:INFO:             IPython: 8.37.0
2025-07-01 13:12:17,422:INFO:          ipywidgets: 8.1.7
2025-07-01 13:12:17,422:INFO:                tqdm: 4.67.1
2025-07-01 13:12:17,422:INFO:               numpy: 1.26.4
2025-07-01 13:12:17,422:INFO:              pandas: 2.1.4
2025-07-01 13:12:17,422:INFO:              jinja2: 3.1.6
2025-07-01 13:12:17,422:INFO:               scipy: 1.11.4
2025-07-01 13:12:17,422:INFO:              joblib: 1.3.2
2025-07-01 13:12:17,422:INFO:             sklearn: 1.4.2
2025-07-01 13:12:17,422:INFO:                pyod: 2.0.5
2025-07-01 13:12:17,422:INFO:            imblearn: 0.13.0
2025-07-01 13:12:17,422:INFO:   category_encoders: 2.7.0
2025-07-01 13:12:17,423:INFO:            lightgbm: 4.6.0
2025-07-01 13:12:17,423:INFO:               numba: 0.61.2
2025-07-01 13:12:17,423:INFO:            requests: 2.32.4
2025-07-01 13:12:17,423:INFO:          matplotlib: 3.7.5
2025-07-01 13:12:17,423:INFO:          scikitplot: 0.3.7
2025-07-01 13:12:17,423:INFO:         yellowbrick: 1.5
2025-07-01 13:12:17,423:INFO:              plotly: 5.24.1
2025-07-01 13:12:17,423:INFO:    plotly-resampler: Not installed
2025-07-01 13:12:17,423:INFO:             kaleido: 1.0.0
2025-07-01 13:12:17,423:INFO:           schemdraw: 0.15
2025-07-01 13:12:17,423:INFO:         statsmodels: 0.14.4
2025-07-01 13:12:17,423:INFO:              sktime: 0.26.0
2025-07-01 13:12:17,423:INFO:               tbats: 1.1.3
2025-07-01 13:12:17,423:INFO:            pmdarima: 2.0.4
2025-07-01 13:12:17,423:INFO:              psutil: 7.0.0
2025-07-01 13:12:17,423:INFO:          markupsafe: 3.0.2
2025-07-01 13:12:17,423:INFO:             pickle5: Not installed
2025-07-01 13:12:17,423:INFO:         cloudpickle: 3.1.1
2025-07-01 13:12:17,423:INFO:         deprecation: 2.1.0
2025-07-01 13:12:17,423:INFO:              xxhash: 3.5.0
2025-07-01 13:12:17,423:INFO:           wurlitzer: Not installed
2025-07-01 13:12:17,423:INFO:PyCaret optional dependencies:
2025-07-01 13:12:17,423:INFO:                shap: Not installed
2025-07-01 13:12:17,423:INFO:           interpret: Not installed
2025-07-01 13:12:17,423:INFO:                umap: Not installed
2025-07-01 13:12:17,423:INFO:     ydata_profiling: Not installed
2025-07-01 13:12:17,423:INFO:  explainerdashboard: Not installed
2025-07-01 13:12:17,423:INFO:             autoviz: Not installed
2025-07-01 13:12:17,423:INFO:           fairlearn: Not installed
2025-07-01 13:12:17,423:INFO:          deepchecks: Not installed
2025-07-01 13:12:17,423:INFO:             xgboost: Not installed
2025-07-01 13:12:17,423:INFO:            catboost: Not installed
2025-07-01 13:12:17,423:INFO:              kmodes: Not installed
2025-07-01 13:12:17,423:INFO:             mlxtend: Not installed
2025-07-01 13:12:17,423:INFO:       statsforecast: Not installed
2025-07-01 13:12:17,423:INFO:        tune_sklearn: Not installed
2025-07-01 13:12:17,423:INFO:                 ray: Not installed
2025-07-01 13:12:17,423:INFO:            hyperopt: Not installed
2025-07-01 13:12:17,423:INFO:              optuna: Not installed
2025-07-01 13:12:17,423:INFO:               skopt: Not installed
2025-07-01 13:12:17,423:INFO:              mlflow: Not installed
2025-07-01 13:12:17,423:INFO:              gradio: Not installed
2025-07-01 13:12:17,423:INFO:             fastapi: 0.115.14
2025-07-01 13:12:17,424:INFO:             uvicorn: 0.34.3
2025-07-01 13:12:17,424:INFO:              m2cgen: Not installed
2025-07-01 13:12:17,424:INFO:           evidently: Not installed
2025-07-01 13:12:17,424:INFO:               fugue: Not installed
2025-07-01 13:12:17,424:INFO:           streamlit: Not installed
2025-07-01 13:12:17,424:INFO:             prophet: Not installed
2025-07-01 13:12:17,424:INFO:None
2025-07-01 13:12:17,424:INFO:Set up data.
2025-07-01 13:12:17,428:INFO:Set up folding strategy.
2025-07-01 13:12:17,428:INFO:Set up train/test split.
2025-07-01 13:12:17,431:INFO:Set up index.
2025-07-01 13:12:17,432:INFO:Assigning column types.
2025-07-01 13:12:17,435:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-07-01 13:12:17,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 13:12:17,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:12:17,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-07-01 13:12:17,534:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:12:17,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,563:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-07-01 13:12:17,605:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:12:17,634:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,676:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-07-01 13:12:17,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,702:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-07-01 13:12:17,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:17,842:INFO:Preparing preprocessing pipeline...
2025-07-01 13:12:17,843:INFO:Set up simple imputation.
2025-07-01 13:12:17,845:INFO:Set up encoding of categorical features.
2025-07-01 13:12:17,894:INFO:Finished creating preprocessing pipeline.
2025-07-01 13:12:17,899:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-07-01 13:12:17,899:INFO:Creating final display dataframe.
2025-07-01 13:12:18,013:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           Outcome
2                   Target type            Binary
3           Original data shape         (768, 10)
4        Transformed data shape         (768, 14)
5   Transformed train set shape         (537, 14)
6    Transformed test set shape         (231, 14)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              ef63
2025-07-01 13:12:18,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:18,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:18,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:18,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-07-01 13:12:18,181:INFO:setup() successfully completed in 0.78s...............
2025-07-01 13:12:18,181:INFO:Initializing create_model()
2025-07-01 13:12:18,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8491A290>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-07-01 13:12:18,181:INFO:Checking exceptions
2025-07-01 13:12:18,183:INFO:Importing libraries
2025-07-01 13:12:18,183:INFO:Copying training dataset
2025-07-01 13:12:18,188:INFO:Defining folds
2025-07-01 13:12:18,188:INFO:Declaring metric variables
2025-07-01 13:12:18,188:INFO:Importing untrained model
2025-07-01 13:12:18,188:INFO:Logistic Regression Imported successfully
2025-07-01 13:12:18,189:INFO:Starting cross validation
2025-07-01 13:12:18,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-07-01 13:12:18,596:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,600:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,610:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,650:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,749:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,762:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,778:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,783:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,783:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,790:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:18,889:INFO:Calculating mean and std
2025-07-01 13:12:18,900:INFO:Creating metrics dataframe
2025-07-01 13:12:18,904:INFO:Finalizing model
2025-07-01 13:12:19,118:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-07-01 13:12:19,119:INFO:Uploading results into container
2025-07-01 13:12:19,120:INFO:Uploading model into container now
2025-07-01 13:12:19,137:INFO:_master_model_container: 1
2025-07-01 13:12:19,137:INFO:_display_container: 2
2025-07-01 13:12:19,138:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-07-01 13:12:19,138:INFO:create_model() successfully completed......................................
2025-07-01 13:12:19,255:INFO:Initializing save_model()
2025-07-01 13:12:19,255:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=models/lr, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Lenovo\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=Fals...
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['age_group'],
                                    transformer=OneHotEncoder(cols=['age_group'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-07-01 13:12:19,255:INFO:Adding model into prep_pipe
2025-07-01 13:12:19,262:INFO:models/lr.pkl saved in current working directory
2025-07-01 13:12:19,273:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Pregnancies', 'Glucose',
                                             'BloodPressure', 'SkinThickness',
                                             'Insulin', 'BMI',
                                             'DiabetesPedigreeFunction',
                                             'Age'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                (...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-07-01 13:12:19,273:INFO:save_model() successfully completed......................................
2025-07-01 13:12:19,356:INFO:Initializing plot_model()
2025-07-01 13:12:19,356:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8491A290>, system=True)
2025-07-01 13:12:19,356:INFO:Checking exceptions
2025-07-01 13:12:19,360:INFO:Preloading libraries
2025-07-01 13:12:19,360:INFO:Copying training dataset
2025-07-01 13:12:19,360:INFO:Plot type: confusion_matrix
2025-07-01 13:12:19,598:INFO:Fitting Model
2025-07-01 13:12:19,598:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-07-01 13:12:19,599:INFO:Scoring test/hold-out set
2025-07-01 13:12:22,665:INFO:Initializing plot_model()
2025-07-01 13:12:22,665:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8491A290>, system=True)
2025-07-01 13:12:22,665:INFO:Checking exceptions
2025-07-01 13:12:22,672:INFO:Preloading libraries
2025-07-01 13:12:22,673:INFO:Copying training dataset
2025-07-01 13:12:22,673:INFO:Plot type: auc
2025-07-01 13:12:22,837:INFO:Fitting Model
2025-07-01 13:12:22,839:WARNING:C:\Users\Lenovo\OneDrive - IRESSEF\Documents\DSWB\Project\Training\Workshop_2025\Github\workshop_github\no-code-app\env1\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2025-07-01 13:12:22,840:INFO:Scoring test/hold-out set
2025-07-01 13:12:24,752:INFO:Initializing plot_model()
2025-07-01 13:12:24,753:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012E8491A290>, system=True)
2025-07-01 13:12:24,754:INFO:Checking exceptions
2025-07-01 13:12:24,757:INFO:Preloading libraries
2025-07-01 13:12:24,757:INFO:Copying training dataset
2025-07-01 13:12:24,759:INFO:Plot type: feature
2025-07-01 13:12:27,052:INFO:Visual Rendered Successfully
2025-07-01 13:12:27,147:INFO:plot_model() successfully completed......................................
